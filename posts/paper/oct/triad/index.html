<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores | yuler's blog</title>
<meta name=keywords content="LSM-Tree">
<meta name=description content="Introduction 本文通过解决LSM-Tree的写放大问题,从而整体上提高其吞吐量. 在真是的生产环境中,作者观察到compaction最高可占据45%的CPU,平均每天有2.5个小时的时间花在compaction上. 显然,compaction和flush是重要的性能挑战,即使它们发生在面向用户的操作的关键路径之外.
主要面向
Background LSM-Tree:
 Memory Component Disk Component Commit Log  User-facing Operation:
 Get(k) Update(k, v) Delete(k)  Internal Operation:
 Flushing Compaction  Movitation 通过实验将正常的LSM与去掉了Disk Component的LSM相比,发现有3x的吞吐损失. 实验确定了昂贵的 I/O 操作的三个主要来源,每个来源对应于LSM-Tree中三个组件中的一个,即
 data-skew unawareness (memory component) premature and iterative compaction (disk component) duplicated writes (commit log)  data-skew unawareness  hot key被频繁更新,造成了commit log快速增长,但$C_m$变化不大. 在$C_m$达到最大容量之前,频繁的触发更新（为什么？）,在L0中打开和存储文件的固定成本不会因实际向其中写入数据而摊销 data-skew导致$C_d$的多层都会有key的冗余,存储了大量的过时数据  premature and iterative compaction Leveling compaction和Size-Tiered Compaction 每次compaciton选择L0中的一个,但L0层的SSTable的key之间有交叉,即使两个SSTable的key交叉范围很大,仍需要进行两次Compaction,data-skew更是会恶化这种情况.
duplicated writes 当$C_m$刷新到$C_d$之后,需要删除掉其在Commit log中的部分.">
<meta name=author content="yuler">
<link rel=canonical href=https://zhangyh.me/posts/paper/oct/triad/>
<meta name=google-site-verification content="G-JP3WQ36T5K">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabcsadf">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.css rel="preload stylesheet" as=style>
<link rel=icon href=https://zhangyh.me/icon/jiaran16.ico>
<link rel=icon type=image/png sizes=16x16 href=https://zhangyh.me/icon/jiaran16.ico>
<link rel=icon type=image/png sizes=32x32 href=https://zhangyh.me/icon/jiaran32.ico>
<link rel=apple-touch-icon href=https://zhangyh.me/%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=https://zhangyh.me/%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.88.1">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css integrity=sha384-zTROYFVGOfTw7JV7KUu8udsvW2fx4lWOsCEDqhBreBwlHI4ioVRtmIvEThzJHGET crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js integrity=sha384-GxNFqL3r9uRJQhR+47eDxuPoNE7yLftQM8LcxzgS4HT73tp970WS/wV5p8UzCOmb crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body)></script>
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JP3WQ36T5K"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-JP3WQ36T5K',{anonymize_ip:!1})}</script>
<meta property="og:title" content="TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores">
<meta property="og:description" content="Introduction 本文通过解决LSM-Tree的写放大问题,从而整体上提高其吞吐量. 在真是的生产环境中,作者观察到compaction最高可占据45%的CPU,平均每天有2.5个小时的时间花在compaction上. 显然,compaction和flush是重要的性能挑战,即使它们发生在面向用户的操作的关键路径之外.
主要面向
Background LSM-Tree:
 Memory Component Disk Component Commit Log  User-facing Operation:
 Get(k) Update(k, v) Delete(k)  Internal Operation:
 Flushing Compaction  Movitation 通过实验将正常的LSM与去掉了Disk Component的LSM相比,发现有3x的吞吐损失. 实验确定了昂贵的 I/O 操作的三个主要来源,每个来源对应于LSM-Tree中三个组件中的一个,即
 data-skew unawareness (memory component) premature and iterative compaction (disk component) duplicated writes (commit log)  data-skew unawareness  hot key被频繁更新,造成了commit log快速增长,但$C_m$变化不大. 在$C_m$达到最大容量之前,频繁的触发更新（为什么？）,在L0中打开和存储文件的固定成本不会因实际向其中写入数据而摊销 data-skew导致$C_d$的多层都会有key的冗余,存储了大量的过时数据  premature and iterative compaction Leveling compaction和Size-Tiered Compaction 每次compaciton选择L0中的一个,但L0层的SSTable的key之间有交叉,即使两个SSTable的key交叉范围很大,仍需要进行两次Compaction,data-skew更是会恶化这种情况.
duplicated writes 当$C_m$刷新到$C_d$之后,需要删除掉其在Commit log中的部分.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://zhangyh.me/posts/paper/oct/triad/"><meta property="og:image" content="https://zhangyh.me/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-10-12T00:00:00+00:00">
<meta property="article:modified_time" content="2021-10-12T00:00:00+00:00"><meta property="og:site_name" content="yuler's blog">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://zhangyh.me/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content="TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores">
<meta name=twitter:description content="Introduction 本文通过解决LSM-Tree的写放大问题,从而整体上提高其吞吐量. 在真是的生产环境中,作者观察到compaction最高可占据45%的CPU,平均每天有2.5个小时的时间花在compaction上. 显然,compaction和flush是重要的性能挑战,即使它们发生在面向用户的操作的关键路径之外.
主要面向
Background LSM-Tree:
 Memory Component Disk Component Commit Log  User-facing Operation:
 Get(k) Update(k, v) Delete(k)  Internal Operation:
 Flushing Compaction  Movitation 通过实验将正常的LSM与去掉了Disk Component的LSM相比,发现有3x的吞吐损失. 实验确定了昂贵的 I/O 操作的三个主要来源,每个来源对应于LSM-Tree中三个组件中的一个,即
 data-skew unawareness (memory component) premature and iterative compaction (disk component) duplicated writes (commit log)  data-skew unawareness  hot key被频繁更新,造成了commit log快速增长,但$C_m$变化不大. 在$C_m$达到最大容量之前,频繁的触发更新（为什么？）,在L0中打开和存储文件的固定成本不会因实际向其中写入数据而摊销 data-skew导致$C_d$的多层都会有key的冗余,存储了大量的过时数据  premature and iterative compaction Leveling compaction和Size-Tiered Compaction 每次compaciton选择L0中的一个,但L0层的SSTable的key之间有交叉,即使两个SSTable的key交叉范围很大,仍需要进行两次Compaction,data-skew更是会恶化这种情况.
duplicated writes 当$C_m$刷新到$C_d$之后,需要删除掉其在Commit log中的部分.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zhangyh.me/posts/"},{"@type":"ListItem","position":2,"name":"TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores","item":"https://zhangyh.me/posts/paper/oct/triad/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores","name":"TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores","description":"Introduction 本文通过解决LSM-Tree的写放大问题,从而整体上提高其吞吐量. 在真是的生产环境中,作者观察到compaction最高可占据45%的CPU,平均每天有2.5个小时的时间花在compaction上. 显然,compaction和flush是重要的性能挑战,即使它们发生在面向用户的操作的关键路径之外.\n主要面向\nBackground LSM-Tree:\n Memory Component Disk Component Commit Log  User-facing Operation:\n Get(k) Update(k, v) Delete(k)  Internal Operation:\n Flushing Compaction  Movitation 通过实验将正常的LSM与去掉了Disk Component的LSM相比,发现有3x的吞吐损失. 实验确定了昂贵的 I/O 操作的三个主要来源,每个来源对应于LSM-Tree中三个组件中的一个,即\n data-skew unawareness (memory component) premature and iterative compaction (disk component) duplicated writes (commit log)  data-skew unawareness  hot key被频繁更新,造成了commit log快速增长,但$C_m$变化不大. 在$C_m$达到最大容量之前,频繁的触发更新（为什么？）,在L0中打开和存储文件的固定成本不会因实际向其中写入数据而摊销 data-skew导致$C_d$的多层都会有key的冗余,存储了大量的过时数据  premature and iterative compaction Leveling compaction和Size-Tiered Compaction 每次compaciton选择L0中的一个,但L0层的SSTable的key之间有交叉,即使两个SSTable的key交叉范围很大,仍需要进行两次Compaction,data-skew更是会恶化这种情况.\nduplicated writes 当$C_m$刷新到$C_d$之后,需要删除掉其在Commit log中的部分.","keywords":["LSM-Tree"],"articleBody":"Introduction 本文通过解决LSM-Tree的写放大问题,从而整体上提高其吞吐量. 在真是的生产环境中,作者观察到compaction最高可占据45%的CPU,平均每天有2.5个小时的时间花在compaction上. 显然,compaction和flush是重要的性能挑战,即使它们发生在面向用户的操作的关键路径之外.\n主要面向\nBackground LSM-Tree:\n Memory Component Disk Component Commit Log  User-facing Operation:\n Get(k) Update(k, v) Delete(k)  Internal Operation:\n Flushing Compaction  Movitation 通过实验将正常的LSM与去掉了Disk Component的LSM相比,发现有3x的吞吐损失. 实验确定了昂贵的 I/O 操作的三个主要来源,每个来源对应于LSM-Tree中三个组件中的一个,即\n data-skew unawareness (memory component) premature and iterative compaction (disk component) duplicated writes (commit log)  data-skew unawareness  hot key被频繁更新,造成了commit log快速增长,但$C_m$变化不大. 在$C_m$达到最大容量之前,频繁的触发更新（为什么？）,在L0中打开和存储文件的固定成本不会因实际向其中写入数据而摊销 data-skew导致$C_d$的多层都会有key的冗余,存储了大量的过时数据  premature and iterative compaction Leveling compaction和Size-Tiered Compaction 每次compaciton选择L0中的一个,但L0层的SSTable的key之间有交叉,即使两个SSTable的key交叉范围很大,仍需要进行两次Compaction,data-skew更是会恶化这种情况.\nduplicated writes 当$C_m$刷新到$C_d$之后,需要删除掉其在Commit log中的部分. 因此，当将内存组件刷新到L0中的磁盘时，系统实际上是在重播它在填充commit log时已经执行的I/O\nTRIAD TRIAD-MEM 利用工作负载的数据倾斜来减少compaction的频率, 只刷新cold key到磁盘,将hot key保留在内存中. 通过separateKey算法选取Top-K个entry作为hot entry, 并将其放到新的$C_m$中. 应当通过数据的先验信息获取到K的合适值,但获取先验信息就要牺牲性能,因此为了性能考虑,将K设置为常数. 在将K个hot entry写入$C_m$之前,需要先写入到新的CommitLog. 实际上,当数据倾斜很严重的时候,往往CommitLog会被写满,而此时的$C_m$还没有满.因此还有一个优化就是,当CommitLog被写满并且$C_m TRIAD-DISK 作用于L0的组件,核心想法是推迟compaction操作,知道L0层中的key有足够的重叠. 通过公式$1 - (UniqueKeys(file_1, file_2, . . . file_n)) / sum(Keys(file_i))$计算重叠率,其中file包括第0层的所有文件以及和第一层有重叠key的文件.\n其中使用HLL来记录每个L0中文件的信息,在已实现的系统中Cassandra和RocksDB使用HLL来决定那些文件被compaction,在这里我们使用HLL来决定何时compaction(现在compaction还是推迟compaction)\nTRIAD-LOG 核心思想是将CommitLog转换为特殊的CL-SSTable,从而省去flush操作.\n问题是CommitLog是无序的,而SSTable为了方便compaction被要求是有序的. 因此在$C_m$中的元素维护其log在CommitLog中的offset,作为索引. 当Flush只需要将index刷新的磁盘中即可.\n读写路径不变. 写唯一的不同就是$C_m$中需要包括(key, value, offset, commitLog) 读唯一的不同是当读$L_0$中的时候,需要通过index进行索引.\ncompaction分析 $L_1$到$L_m$的compaction不变 $L_0$到$L_1$的compaction需要读index和commitLog,还是可以通过merge-sort来合并.\n","wordCount":"107","inLanguage":"en","datePublished":"2021-10-12T00:00:00Z","dateModified":"2021-10-12T00:00:00Z","author":{"@type":"Person","name":"yuler"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zhangyh.me/posts/paper/oct/triad/"},"publisher":{"@type":"Organization","name":"yuler's blog","logo":{"@type":"ImageObject","url":"https://zhangyh.me/icon/jiaran16.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://zhangyh.me/ accesskey=h title="Home (Alt + H)">Home</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://zhangyh.me/archives/ title=archives>
<span>archives</span>
</a>
</li>
<li>
<a href=https://zhangyh.me/categories/ title=categories>
<span>categories</span>
</a>
</li>
<li>
<a href=https://zhangyh.me/tags/ title=tags>
<span>tags</span>
</a>
</li>
<li>
<a href=https://zhangyh.me/search/ title="search (Alt + /)" accesskey=/>
<span>search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://zhangyh.me/>Home</a>&nbsp;»&nbsp;<a href=https://zhangyh.me/posts/>Posts</a></div>
<h1 class=post-title>
TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores
</h1>
<div class=post-meta>10-12&nbsp;·&nbsp;yuler&nbsp;|&nbsp;<a href=https://github.com/yu1er/blog-src/tree/main/content/posts/paper/oct/TRIAD.md rel="noopener noreferrer" target=_blank>Edit</a>
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#introduction aria-label=Introduction>Introduction</a></li>
<li>
<a href=#background aria-label=Background>Background</a></li>
<li>
<a href=#movitation aria-label=Movitation>Movitation</a><ul>
<li>
<a href=#data-skew-unawareness aria-label="data-skew unawareness">data-skew unawareness</a></li>
<li>
<a href=#premature-and-iterative-compaction aria-label="premature and iterative compaction">premature and iterative compaction</a></li>
<li>
<a href=#duplicated-writes aria-label="duplicated writes">duplicated writes</a></li></ul>
</li>
<li>
<a href=#triad aria-label=TRIAD>TRIAD</a><ul>
<li>
<a href=#triad-mem aria-label=TRIAD-MEM>TRIAD-MEM</a></li>
<li>
<a href=#triad-disk aria-label=TRIAD-DISK>TRIAD-DISK</a></li>
<li>
<a href=#triad-log aria-label=TRIAD-LOG>TRIAD-LOG</a>
</li>
</ul>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2>
<p>本文通过解决LSM-Tree的写放大问题,从而整体上提高其吞吐量.
在真是的生产环境中,作者观察到compaction最高可占据45%的CPU,平均每天有2.5个小时的时间花在compaction上.
显然,compaction和flush是重要的性能挑战,即使它们发生在面向用户的操作的关键路径之外.</p>
<p>主要面向</p>
<h2 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h2>
<p>LSM-Tree:</p>
<ul>
<li>Memory Component</li>
<li>Disk Component</li>
<li>Commit Log</li>
</ul>
<p>User-facing Operation:</p>
<ul>
<li>Get(k)</li>
<li>Update(k, v)</li>
<li>Delete(k)</li>
</ul>
<p>Internal Operation:</p>
<ul>
<li>Flushing</li>
<li>Compaction</li>
</ul>
<h2 id=movitation>Movitation<a hidden class=anchor aria-hidden=true href=#movitation>#</a></h2>
<p>通过实验将正常的LSM与去掉了Disk Component的LSM相比,发现有3x的吞吐损失.
实验确定了昂贵的 I/O 操作的三个主要来源,每个来源对应于LSM-Tree中三个组件中的一个,即</p>
<ul>
<li>data-skew unawareness (memory component)</li>
<li>premature and iterative compaction (disk component)</li>
<li>duplicated writes (commit log)</li>
</ul>
<h3 id=data-skew-unawareness>data-skew unawareness<a hidden class=anchor aria-hidden=true href=#data-skew-unawareness>#</a></h3>
<ol>
<li>hot key被频繁更新,造成了commit log快速增长,但$C_m$变化不大.
在$C_m$达到最大容量之前,频繁的触发更新（为什么？）,在L0中打开和存储文件的固定成本不会因实际向其中写入数据而摊销</li>
<li>data-skew导致$C_d$的多层都会有key的冗余,存储了大量的过时数据</li>
</ol>
<h3 id=premature-and-iterative-compaction>premature and iterative compaction<a hidden class=anchor aria-hidden=true href=#premature-and-iterative-compaction>#</a></h3>
<p>Leveling compaction和Size-Tiered Compaction
每次compaciton选择L0中的一个,但L0层的SSTable的key之间有交叉,即使两个SSTable的key交叉范围很大,仍需要进行两次Compaction,data-skew更是会恶化这种情况.</p>
<h3 id=duplicated-writes>duplicated writes<a hidden class=anchor aria-hidden=true href=#duplicated-writes>#</a></h3>
<p>当$C_m$刷新到$C_d$之后,需要删除掉其在Commit log中的部分.
因此，当将内存组件刷新到L0中的磁盘时，系统实际上是在重播它在填充commit log时已经执行的I/O</p>
<h2 id=triad>TRIAD<a hidden class=anchor aria-hidden=true href=#triad>#</a></h2>
<h3 id=triad-mem>TRIAD-MEM<a hidden class=anchor aria-hidden=true href=#triad-mem>#</a></h3>
<p><img loading=lazy src=/img/TRIAD-MEM-before.webp alt>
<img loading=lazy src=/img/TRIAD-MEM-after.webp alt>
<img loading=lazy src=/img/TRIAD-algorithm-1.webp alt>
</p>
<p>利用工作负载的数据倾斜来减少compaction的频率, 只刷新<em>cold key</em>到磁盘,将<em>hot key</em>保留在内存中.
通过<em>separateKey</em>算法选取Top-K个entry作为hot entry, 并将其放到新的$C_m$中.
应当通过数据的先验信息获取到K的合适值,但获取先验信息就要牺牲性能,因此为了性能考虑,将K设置为常数.
在将K个hot entry写入$C_m$之前,需要先写入到新的CommitLog.
实际上,当数据倾斜很严重的时候,往往CommitLog会被写满,而此时的$C_m$还没有满.因此还有一个优化就是,当CommitLog被写满并且$C_m &lt; FLUSH_TH$时,创建并写入新的CommitLog,而不进行Flush. (参考algorithm-1)</p>
<h3 id=triad-disk>TRIAD-DISK<a hidden class=anchor aria-hidden=true href=#triad-disk>#</a></h3>
<p><img loading=lazy src=/img/TRIAD-DISK-overlap-ratio.webp alt>
作用于L0的组件,核心想法是推迟compaction操作,知道L0层中的key有足够的重叠.
通过公式$1 - (UniqueKeys(file_1, file_2, . . . file_n)) / sum(Keys(file_i))$计算重叠率,其中file包括第0层的所有文件以及和第一层有重叠key的文件.</p>
<p>其中使用HLL来记录每个L0中文件的信息,在已实现的系统中Cassandra和RocksDB使用HLL来决定那些文件被compaction,在这里我们使用HLL来决定何时compaction(现在compaction还是推迟compaction)</p>
<h3 id=triad-log>TRIAD-LOG<a hidden class=anchor aria-hidden=true href=#triad-log>#</a></h3>
<p>核心思想是将CommitLog转换为特殊的CL-SSTable,从而省去flush操作.</p>
<p>问题是CommitLog是无序的,而SSTable为了方便compaction被要求是有序的. 因此在$C_m$中的元素维护其log在CommitLog中的offset,作为索引. 当Flush只需要将index刷新的磁盘中即可.</p>
<p>读写路径不变.
写唯一的不同就是$C_m$中需要包括(key, value, offset, commitLog)
读唯一的不同是当读$L_0$中的时候,需要通过index进行索引.</p>
<p>compaction分析
$L_1$到$L_m$的compaction不变
$L_0$到$L_1$的compaction需要读index和commitLog,还是可以通过merge-sort来合并.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://zhangyh.me/tags/lsm-tree/>LSM-Tree</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://zhangyh.me/posts/leetcode/monotone-stack/>
<span class=title>« Prev Page</span>
<br>
<span>单调栈题集</span>
</a>
<a class=next href=https://zhangyh.me/posts/cpp/problem-list/>
<span class=title>Next Page »</span>
<br>
<span>cpp问题清单</span>
</a>
</nav>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://zhangyh.me/>yuler's blog</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>