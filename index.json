[{"content":"单调栈 单调栈可以保证栈内元素线性有序,同时复杂度为$O(n)$.\n通常的trick会在首尾处添加两个哨兵元素.\n题目 84. 柱状图中最大的矩形 很经典的单调栈用法.\nclass Solution { public: int largestRectangleArea(vector\u0026lt;int\u0026gt;\u0026amp; heights) { vector\u0026lt;int\u0026gt; nums(heights.size() + 2); copy(begin(heights), end(heights), begin(nums) + 1); int n = nums.size(); stack\u0026lt;int\u0026gt; stk; stk.push(0); int ans = 0; for (int i = 1; i \u0026lt; n; i++) { while (nums[i] \u0026lt; nums[stk.top()]) { int h = nums[stk.top()]; stk.pop(); int w = i - stk.top() - 1; ans = max(ans, h * w); } stk.push(i); } return ans; } };  时间复杂度: $O(n)$ 空间复杂度: $O(n)$  85. 最大矩形 可以将题目转化为求m个84. 柱状图中最大的矩形的最大值.\nclass Solution { public: int maximalRectangle(vector\u0026lt;vector\u0026lt;char\u0026gt;\u0026gt;\u0026amp; matrix) { int m = matrix.size(); if (m == 0) return 0; int n = matrix[0].size(); if (n == 0) return 0; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; pre(m, vector\u0026lt;int\u0026gt;(n + 2, 0)); for (int i = 0; i \u0026lt; m; i++) { for (int j = 0; j \u0026lt; n; j++) { if (matrix[i][j] == \u0026#39;1\u0026#39;) pre[i][j + 1] = (i == 0? 0 : pre[i-1][j + 1]) + 1; } } int ans = 0; for (int i = 0; i \u0026lt; m; i++){ ans = max(ans, help(pre[i], n + 2)); } return ans; } int help(const vector\u0026lt;int\u0026gt;\u0026amp; nums, int n) { stack\u0026lt;int\u0026gt; stk; stk.push(0); int ans = 0; for (int i = 1; i \u0026lt; n; i++) { while (nums[i] \u0026lt; nums[stk.top()]) { int h = nums[stk.top()]; stk.pop(); int w = i - stk.top() - 1; ans = max(ans, w * h); } stk.push(i); } return ans; } };  时间复杂度: $O(m * n)$ 空间复杂度: $O(m * n)$  ","permalink":"https://zhangyh.me/posts/leetcode/monotone-stack/","summary":"单调栈 单调栈可以保证栈内元素线性有序,同时复杂度为$O(n)$.\n通常的trick会在首尾处添加两个哨兵元素.\n题目 84. 柱状图中最大的矩形 很经典的单调栈用法.\nclass Solution { public: int largestRectangleArea(vector\u0026lt;int\u0026gt;\u0026amp; heights) { vector\u0026lt;int\u0026gt; nums(heights.size() + 2); copy(begin(heights), end(heights), begin(nums) + 1); int n = nums.size(); stack\u0026lt;int\u0026gt; stk; stk.push(0); int ans = 0; for (int i = 1; i \u0026lt; n; i++) { while (nums[i] \u0026lt; nums[stk.top()]) { int h = nums[stk.top()]; stk.pop(); int w = i - stk.top() - 1; ans = max(ans, h * w); } stk.","title":"单调栈题集"},{"content":"问题1 #include \u0026lt;iostream\u0026gt; class A { public: virtual void func(int val = 1) {std::cout \u0026lt;\u0026lt; \u0026#34;A-\u0026gt;\u0026#34; \u0026lt;\u0026lt; val \u0026lt;\u0026lt; std::endl; } virtual void test(){func();} }; class B : public A { public: void func(int val = 0) {std::cout \u0026lt;\u0026lt; \u0026#34;B-\u0026gt;\u0026#34; \u0026lt;\u0026lt; val \u0026lt;\u0026lt; std::endl;} }; int main () { B* b = new B; b-\u0026gt;test(); return 0; } 输出  B-\u0026gt;1\n 解释 参考《Effective c++》条款37: 绝不重新定义继承而来的缺省默认值. 因为虚函数是动态绑定,因此b实际指向的就是b.而默认参数是静态绑定,是由编译器决定的.\n test函数是A的,test内部调用func实际上是this-\u0026gt;func,func是个虚函数而且在B中被重写了,所以有动态绑定. 这里的this运行时类型是B,所以调用B的func,但是缺省参数实际上是静态绑定的,所以输出的val是A中的那个val.\n ","permalink":"https://zhangyh.me/posts/cpp/problem-list/","summary":"问题1 #include \u0026lt;iostream\u0026gt; class A { public: virtual void func(int val = 1) {std::cout \u0026lt;\u0026lt; \u0026#34;A-\u0026gt;\u0026#34; \u0026lt;\u0026lt; val \u0026lt;\u0026lt; std::endl; } virtual void test(){func();} }; class B : public A { public: void func(int val = 0) {std::cout \u0026lt;\u0026lt; \u0026#34;B-\u0026gt;\u0026#34; \u0026lt;\u0026lt; val \u0026lt;\u0026lt; std::endl;} }; int main () { B* b = new B; b-\u0026gt;test(); return 0; } 输出  B-\u0026gt;1\n 解释 参考《Effective c++》条款37: 绝不重新定义继承而来的缺省默认值. 因为虚函数是动态绑定,因此b实际指向的就是b.而默认参数是静态绑定,是由编译器决定的.\n test函数是A的,test内部调用func实际上是this-\u0026gt;func,func是个虚函数而且在B中被重写了,所以有动态绑定. 这里的this运行时类型是B,所以调用B的func,但是缺省参数实际上是静态绑定的,所以输出的val是A中的那个val.","title":"cpp问题清单"},{"content":"给定一个pair\u0026lt;int, int\u0026gt;数组,通过自定义排序顺序决定优先队列中的顺序.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; nums{{4, 1}, {8, 2}, {1, 9}, {8, 1}, {8, 4}, {3, 7}}; 仿函数 (推荐) 仿函数的出现就是为了解决函数指针在作为函数参数向函数传递时的局限性问题. 通过重写类的operator(),使该类具有函数的功能.\nstruct cmp { bool operator() (const pair\u0026lt;int, int\u0026gt; \u0026amp;a, const pair\u0026lt;int, int\u0026gt; \u0026amp;b) { return a.first == b.first? a.second \u0026lt; b.second : a.first \u0026lt; b.first; } }; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, cmp\u0026gt; pq; lambda 通过c++11新特性的lambda和delctype,可以避免重新定义类. 但需要注意,lambda函数需要通过构造函数的参数传递.\nauto a = [](const pair\u0026lt;int, int\u0026gt; \u0026amp; a, const pair\u0026lt;int, int\u0026gt; \u0026amp;b){ return a.first == b.first? a.second \u0026lt; b.second : a.first \u0026lt; b.first; }; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, decltype(a)\u0026gt; pq(a); 自定义类 默认对于自定义类的比较,priority_queue直接使用其operator\u0026lt;函数,因此如果需要比较,需要时先该运算符函数. 这种方法比较笨重,不适用自定义内置类的比较顺序.\nstruct node { int _a, _b; node(int a, int b) : _a{a}, _b{b}{}; bool operator\u0026lt;(const node \u0026amp; r) const { return _a == r._a? _b \u0026lt; r._b: _a \u0026lt; r._a; } }; vector\u0026lt;node\u0026gt; nums{{4, 1}, {8, 2}, {1, 9}, {8, 1}, {8, 4}, {3, 7}}; priority_queue\u0026lt;node\u0026gt; pq; ","permalink":"https://zhangyh.me/posts/cpp/priority-queue-custom-comparator/","summary":"给定一个pair\u0026lt;int, int\u0026gt;数组,通过自定义排序顺序决定优先队列中的顺序.\nvector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; nums{{4, 1}, {8, 2}, {1, 9}, {8, 1}, {8, 4}, {3, 7}}; 仿函数 (推荐) 仿函数的出现就是为了解决函数指针在作为函数参数向函数传递时的局限性问题. 通过重写类的operator(),使该类具有函数的功能.\nstruct cmp { bool operator() (const pair\u0026lt;int, int\u0026gt; \u0026amp;a, const pair\u0026lt;int, int\u0026gt; \u0026amp;b) { return a.first == b.first? a.second \u0026lt; b.second : a.first \u0026lt; b.first; } }; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, cmp\u0026gt; pq; lambda 通过c++11新特性的lambda和delctype,可以避免重新定义类. 但需要注意,lambda函数需要通过构造函数的参数传递.\nauto a = [](const pair\u0026lt;int, int\u0026gt; \u0026amp; a, const pair\u0026lt;int, int\u0026gt; \u0026amp;b){ return a.first == b.","title":"priority_queue自定义排序"},{"content":"Shortcomings of current LSMs   线程的可扩展性 LevelDB允许一定程度的并发写，但内部是将写入操作写到了一个队列中，最后仍是顺序执行。 HyperLevelDB、RocksDB、cLSM做了一定程度的并行优化\n  内存的可扩展性 内存中组件可以是有序跳表，也可以是无序哈希表，但二者都不适合应用到更大的内存中。 对于跳表而言，读写时间复杂度都是$O(logn)$，有序性一定程度优化了范围查询，并加速了flush过程。但一般来说，读取操作都要到达磁盘，因此，跳表对写入的负面影响大于对读取的正面影响。对于更大内存中更大的跳表，读写延迟往往会提高。 对于哈希表而言，读写时间复杂度都是$O(1)$，无序性增加了范围查询和flush过程的工作量。但哈希表需要更长的时间排序，size越大，所需时间越长，会阻塞上层的写入操作。\n  FloDB Design 设计了两层的内存组件，上层是small、fast、unordered的Membuffer，下层是larger、ordered的Memtable。两层都是可并行的数据结构，数据流跟LSM类似，从最小的Membuffer，流向Memtable，直到磁盘上的SStable。\nGet 搜索顺序：Membuffer -\u0026gt; Memtable -\u0026gt; SStable\nUpdate Put和Delete操作和Update是相似的。 首先尝试在Membuffer更新，如果Membuffer满了，就直接在Memtable上完成更新。（假如说Membuffer或Memtable上有对应值的话，更新就是in-place的）\n替代的方案就是mulit-version更新，然而对比起来，in-place更新在skewed的工作负载上具有更好的表现。\nScan 扫描Memtable和disk，同时允许Membuffer进行并行的update。 挑战1：Membuffer有对应的数据，因此扫描前先清空Membuffer到Memtable上。 挑战2：long-time的扫描导致Membuffer变满，允许writer和sanner在Memtable上并行。这个时候可能会导致不一致性，因此我们记录scan时的sequence number，扫描后的结果中如果有大于该值的entry，则重新扫描。\nFloDB Implementation 明确了四各方面:\n Membuffer和Memtable数据结构的选择 数据从Membuffer到Memtable移动的机制 新颖的多插入操作用于简化 Memtable 和 Membuffer 之间的数据流 面向用户的操作的实现  Memory Component Implementation Membuffer -\u0026gt; Hash Table Memtable -\u0026gt; Skiplist\nInteraction Between Levels 包括persisting和draining.\nSkiplist Multi-inserts 实验显示，多线程下hash table比skiplist块一到两个数量级。因此应该尽快地完成移动，使得update在hash table上进行。\n批量的插入多个kv对到skiplist中，而不是挨个插入。核心思想是我们能直接利用前一个kv对的pre指针，而不是重新找，有path-reuse的思想在里面。\n并行性。插入和insert、read并行。\nkey的临近度决定了path-reuse的效果。\n","permalink":"https://zhangyh.me/posts/paper/sep/flodb/","summary":"Shortcomings of current LSMs   线程的可扩展性 LevelDB允许一定程度的并发写，但内部是将写入操作写到了一个队列中，最后仍是顺序执行。 HyperLevelDB、RocksDB、cLSM做了一定程度的并行优化\n  内存的可扩展性 内存中组件可以是有序跳表，也可以是无序哈希表，但二者都不适合应用到更大的内存中。 对于跳表而言，读写时间复杂度都是$O(logn)$，有序性一定程度优化了范围查询，并加速了flush过程。但一般来说，读取操作都要到达磁盘，因此，跳表对写入的负面影响大于对读取的正面影响。对于更大内存中更大的跳表，读写延迟往往会提高。 对于哈希表而言，读写时间复杂度都是$O(1)$，无序性增加了范围查询和flush过程的工作量。但哈希表需要更长的时间排序，size越大，所需时间越长，会阻塞上层的写入操作。\n  FloDB Design 设计了两层的内存组件，上层是small、fast、unordered的Membuffer，下层是larger、ordered的Memtable。两层都是可并行的数据结构，数据流跟LSM类似，从最小的Membuffer，流向Memtable，直到磁盘上的SStable。\nGet 搜索顺序：Membuffer -\u0026gt; Memtable -\u0026gt; SStable\nUpdate Put和Delete操作和Update是相似的。 首先尝试在Membuffer更新，如果Membuffer满了，就直接在Memtable上完成更新。（假如说Membuffer或Memtable上有对应值的话，更新就是in-place的）\n替代的方案就是mulit-version更新，然而对比起来，in-place更新在skewed的工作负载上具有更好的表现。\nScan 扫描Memtable和disk，同时允许Membuffer进行并行的update。 挑战1：Membuffer有对应的数据，因此扫描前先清空Membuffer到Memtable上。 挑战2：long-time的扫描导致Membuffer变满，允许writer和sanner在Memtable上并行。这个时候可能会导致不一致性，因此我们记录scan时的sequence number，扫描后的结果中如果有大于该值的entry，则重新扫描。\nFloDB Implementation 明确了四各方面:\n Membuffer和Memtable数据结构的选择 数据从Membuffer到Memtable移动的机制 新颖的多插入操作用于简化 Memtable 和 Membuffer 之间的数据流 面向用户的操作的实现  Memory Component Implementation Membuffer -\u0026gt; Hash Table Memtable -\u0026gt; Skiplist\nInteraction Between Levels 包括persisting和draining.\nSkiplist Multi-inserts 实验显示，多线程下hash table比skiplist块一到两个数量级。因此应该尽快地完成移动，使得update在hash table上进行。\n批量的插入多个kv对到skiplist中，而不是挨个插入。核心思想是我们能直接利用前一个kv对的pre指针，而不是重新找，有path-reuse的思想在里面。\n并行性。插入和insert、read并行。\nkey的临近度决定了path-reuse的效果。","title":"FloDB: Unlocking Memory in Persistent Key-Value Stores"},{"content":"Movitation  传统的merge policy  Level Merge Policy和Tiered Merge Policy在读写放大方面各有优势. 前者相当于单层的Tiered,保证了单层数据的有序性,减少了读放大,但要维护这种有序性,就需要频繁的merge,因此造成了严重的写放大. 后者对有序性的要求并不严格,它只要求每个group的key range互不交叉,允许sstable之间的key交叉.\n工作负载的空间局部性  作者对ZippyDB(facebook)的工作负载分析发现,少部分的key被读写多次,大部分的key被读写的次数很少.\nDesign 作者提出了疑问:\n How to resolve the read amplification problem induced by the tiering merge policy while maintaining its low write amplification?\n 根据key-space的不同access pattern,有选择的采用Tiering和Leveling Merge policy. 通过追踪每层中的key-space的访问强度,来决定设置T的值为1还是configured threshold.\nSpatially Fragmented LSM-TREE (SFM) 每层通过随机的边界分为不同的key-space.边界的选取方式类似于PebblesDB. 如果一个栈的key-range被认为是读密集的,则设置T为1,否则,按照原有的配置设置.\n合并策略如上图\n 读超过stack阈值的文件到内存 在内存中进行merge 按照下层的key边界进行切片 新SSTable被刷新到下层 添加到key对应的栈  B. Read Intensity Identification 如何判断读的强度呢? 统计每个段的读写次数.对于读操作,即使读取的key不存在,也是要计入读取次数的. 对于写操作,统计每次merge后的sstable中的kv对的数量. 通过对比每个stack的r/w和整体平均的r/w来判断其为hot还是cold. 根据每个stack的hot还是cold属性,来决定key-space的访问强度.\nMetadata Managment 通过StackMetadata的数据结构来管理每个stack的元信息.\n不仅存储了readCount和writeCount, 还额外记录了stack的currentThreshold. 每当触发合并操作时，根据识别的读取强度将每个堆栈的阈值 currentThreshold 定义为 1 或 T.\nHot Inheritance merge操作后,上层stack对应的粗粒度的key被细分为下层若干个stack. 对于下层stack, 在收集到足够的数据之前,很难判断其是hot还是cold的. 因此很容易导致T的误判. 因此作者提出了名为热度继承的概念,\n按照这种设计原则，在merge时，StackMetadata的热度信息（例如，readCount、writeCount）从上一级继承到下一级。 但在merge之后，这些新栈的r/w热度是独立于父栈估计的。\nInitialization Of Hotness Information 过期stack的热度信息如何处理? 记录一个stackCount(记录stack上的rw数)和一个currentCount(记录全局的rw数),当merge之后,上层的stack变为过期,此时计算$elapsedCount = currentCount - stackCount$ 当elapsedCount大于lifeCount时,重置hotness信息. 当elapsedCount小于lifeCount时,保持hoteness信息不变.\n我的思考时,通过lifeCount来估算merge大致经过的时间,如果时间过长,他的hot/cold属性可能已经发生变化,就需要改变. 如果时间经过的较短,则认为其hot/cold属性没有发生变化.\nExperiment ","permalink":"https://zhangyh.me/posts/paper/sep/sfm/","summary":"Movitation  传统的merge policy  Level Merge Policy和Tiered Merge Policy在读写放大方面各有优势. 前者相当于单层的Tiered,保证了单层数据的有序性,减少了读放大,但要维护这种有序性,就需要频繁的merge,因此造成了严重的写放大. 后者对有序性的要求并不严格,它只要求每个group的key range互不交叉,允许sstable之间的key交叉.\n工作负载的空间局部性  作者对ZippyDB(facebook)的工作负载分析发现,少部分的key被读写多次,大部分的key被读写的次数很少.\nDesign 作者提出了疑问:\n How to resolve the read amplification problem induced by the tiering merge policy while maintaining its low write amplification?\n 根据key-space的不同access pattern,有选择的采用Tiering和Leveling Merge policy. 通过追踪每层中的key-space的访问强度,来决定设置T的值为1还是configured threshold.\nSpatially Fragmented LSM-TREE (SFM) 每层通过随机的边界分为不同的key-space.边界的选取方式类似于PebblesDB. 如果一个栈的key-range被认为是读密集的,则设置T为1,否则,按照原有的配置设置.\n合并策略如上图\n 读超过stack阈值的文件到内存 在内存中进行merge 按照下层的key边界进行切片 新SSTable被刷新到下层 添加到key对应的栈  B. Read Intensity Identification 如何判断读的强度呢? 统计每个段的读写次数.对于读操作,即使读取的key不存在,也是要计入读取次数的. 对于写操作,统计每次merge后的sstable中的kv对的数量. 通过对比每个stack的r/w和整体平均的r/w来判断其为hot还是cold. 根据每个stack的hot还是cold属性,来决定key-space的访问强度.\nMetadata Managment 通过StackMetadata的数据结构来管理每个stack的元信息.","title":"SFM: Mitigating Read/Write Amplification Problem of LSM-Tree-Based Key-Value Stores"},{"content":"本文旨在解决LSM-Tree的长尾问题，长尾问题的根源主要是客户端操作和LSM-Tree内部操作的互相干扰。 客户端操作：write 内部操作: flush、compaction\nExperiment study of tail latency  实验一：对比RocksDB和RocksDB without flushing. RocksDB without flushing: 要flush的immutable memtable直接丢弃 实验二：Rate-limited RocksDB 实验三：RocksDB with increased Memtable 实验四：TRAID 实验五：PebblesDB  作者对目前最新的LSM-Tree数据库RocksDB、TRIAD、PebblesDB进行了实验并得出三点结论。\n 长尾的主要原因是被写满的memtable阻塞了write。 有两个原因导致了这种情况：第一，磁盘上的L0-L1 compaction跟不上写入的速度，导致L0被写满。第二，意外的有大量的compaction在同时进行，占据了大量的IO，导致flush因为有限的带宽而变慢，使得memtable变满。 简单的限制内部操作带宽, 并不能解决flush带宽受限的问题，长远来看反而会加剧这种问题。这种方法能够推迟压缩，但增加了在未来某个时候同时发生compaction的可能性。 提高吞吐量的方法，例如选择性地启动压缩或仅在最高level执行压缩，在短期内避免了延迟峰值，但从长远来看会加剧问题，因为它们也会增加在稍后的某个时间点进行许多并发压缩的可能性。  推论： 由1得出推论：内部操作并不是完全平等的。更low-level的操作是关键的，因为未能及时完成它们可能会导致客户端操作停滞。 由2，3得出推论：必须进行长时间的测试，避免问题未被发现。 (因为写入的数据量不够的话，无法体现更底层的compaction操作对系统的影响。)\nSILK Design principles  有选择的分配带宽。 遇到峰值流量时，分配更多的带宽给low-level，减缓high-level的压缩。 在闲时，利用短暂的低负载时期来促进内部操作的处理 优先处理更low-level的操作 给内部操作指定优先级: flush \u0026gt; L0-L1 compaction \u0026gt; high-level compaction 抢占式compaction 允许更low-level的compaction抢占high-level的compaction  Implementation  有选择的分配带宽 有优先次序和可抢占的内部操作 系统内部维护两个线程池：高优先级池用于flush,低优先级池用于compaction.   Flush: 有专门的线程池，在mem被写满之前，提供稳定的一定量的带宽，以保证不断的写入。多个内存组件和多个线程可能保证较长的性能高峰。 L0-L1 compaction: 和high-level的compaction共用线程，该过程需要保证L0有足够的空间供flush。如果需要进行L0-L1的compaction，并且目前没有可用线程，那么就会抢占high-leve compaction的线程。 high-level compaction: 线程维护在低优先级线程池  ","permalink":"https://zhangyh.me/posts/paper/sep/silk/","summary":"本文旨在解决LSM-Tree的长尾问题，长尾问题的根源主要是客户端操作和LSM-Tree内部操作的互相干扰。 客户端操作：write 内部操作: flush、compaction\nExperiment study of tail latency  实验一：对比RocksDB和RocksDB without flushing. RocksDB without flushing: 要flush的immutable memtable直接丢弃 实验二：Rate-limited RocksDB 实验三：RocksDB with increased Memtable 实验四：TRAID 实验五：PebblesDB  作者对目前最新的LSM-Tree数据库RocksDB、TRIAD、PebblesDB进行了实验并得出三点结论。\n 长尾的主要原因是被写满的memtable阻塞了write。 有两个原因导致了这种情况：第一，磁盘上的L0-L1 compaction跟不上写入的速度，导致L0被写满。第二，意外的有大量的compaction在同时进行，占据了大量的IO，导致flush因为有限的带宽而变慢，使得memtable变满。 简单的限制内部操作带宽, 并不能解决flush带宽受限的问题，长远来看反而会加剧这种问题。这种方法能够推迟压缩，但增加了在未来某个时候同时发生compaction的可能性。 提高吞吐量的方法，例如选择性地启动压缩或仅在最高level执行压缩，在短期内避免了延迟峰值，但从长远来看会加剧问题，因为它们也会增加在稍后的某个时间点进行许多并发压缩的可能性。  推论： 由1得出推论：内部操作并不是完全平等的。更low-level的操作是关键的，因为未能及时完成它们可能会导致客户端操作停滞。 由2，3得出推论：必须进行长时间的测试，避免问题未被发现。 (因为写入的数据量不够的话，无法体现更底层的compaction操作对系统的影响。)\nSILK Design principles  有选择的分配带宽。 遇到峰值流量时，分配更多的带宽给low-level，减缓high-level的压缩。 在闲时，利用短暂的低负载时期来促进内部操作的处理 优先处理更low-level的操作 给内部操作指定优先级: flush \u0026gt; L0-L1 compaction \u0026gt; high-level compaction 抢占式compaction 允许更low-level的compaction抢占high-level的compaction  Implementation  有选择的分配带宽 有优先次序和可抢占的内部操作 系统内部维护两个线程池：高优先级池用于flush,低优先级池用于compaction.   Flush: 有专门的线程池，在mem被写满之前，提供稳定的一定量的带宽，以保证不断的写入。多个内存组件和多个线程可能保证较长的性能高峰。 L0-L1 compaction: 和high-level的compaction共用线程，该过程需要保证L0有足够的空间供flush。如果需要进行L0-L1的compaction，并且目前没有可用线程，那么就会抢占high-leve compaction的线程。 high-level compaction: 线程维护在低优先级线程池  ","title":"SILK: Preventing Latency Spikes in Log-Structured Merge Key-Value Stores "},{"content":"第259次周赛 A. 执行操作后的变量值  时间复杂度: $O(n)$ 空间复杂度: $O(1)$  class Solution { public: int finalValueAfterOperations(vector\u0026lt;string\u0026gt;\u0026amp; operations) { int X = 0; for (auto \u0026amp; s: operations) { if (s[1] == \u0026#39;+\u0026#39;) X++; else X--; } return X; } }; B. 数组美丽值求和 通过正反两次遍历记录每个值左边的最大值和右边的最小值.\n 时间复杂度: $O(n)$ 空间复杂度: $O(n)$  class Solution { public: int sumOfBeauties(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); vector\u0026lt;int\u0026gt; left(n, INT_MIN), right(n, INT_MAX); int ans = 0; left[0] = nums[0]; right[n - 1] = nums[n - 1]; for (int i = 1; i \u0026lt; n; i++) left[i] = max(left[i-1], nums[i]); for (int i = n - 2; i \u0026gt;= 0; i--) right[i] = min(right[i + 1], nums[i]); for (int i = 1; i \u0026lt; n - 1; i++) { if (left[i - 1] \u0026lt; nums[i] \u0026amp;\u0026amp; nums[i] \u0026lt; right[i + 1]) ans +=2; else if (nums[i - 1] \u0026lt; nums[i] \u0026amp;\u0026amp; nums[i] \u0026lt; nums[i + 1]) ans++; } return ans; } }; C. 检测正方形 注意轴对齐正方形定义,可通过一个map来记录所有的坐标.\nclass DetectSquares { unordered_map\u0026lt;int, unordered_map\u0026lt;int, int\u0026gt;\u0026gt; mp; public: DetectSquares() { } void add(vector\u0026lt;int\u0026gt; point) { mp[point[0]][point[1]]++; } int count(vector\u0026lt;int\u0026gt; point) { int x = point[0], y = point[1]; int ans = 0; for (auto [y1, c]: mp[x]) { if (y1 == y) continue; int len = abs(y1 - y); ans += (mp[x + len][y1] * mp[x+len][y] + mp[x-len][y1] * mp[x-len][y]) * c; } return ans; } }; TODO: 重复 K 次的最长子序列 ","permalink":"https://zhangyh.me/posts/leetcode/weekly-contest-259/","summary":"第259次周赛 A. 执行操作后的变量值  时间复杂度: $O(n)$ 空间复杂度: $O(1)$  class Solution { public: int finalValueAfterOperations(vector\u0026lt;string\u0026gt;\u0026amp; operations) { int X = 0; for (auto \u0026amp; s: operations) { if (s[1] == \u0026#39;+\u0026#39;) X++; else X--; } return X; } }; B. 数组美丽值求和 通过正反两次遍历记录每个值左边的最大值和右边的最小值.\n 时间复杂度: $O(n)$ 空间复杂度: $O(n)$  class Solution { public: int sumOfBeauties(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int n = nums.size(); vector\u0026lt;int\u0026gt; left(n, INT_MIN), right(n, INT_MAX); int ans = 0; left[0] = nums[0]; right[n - 1] = nums[n - 1]; for (int i = 1; i \u0026lt; n; i++) left[i] = max(left[i-1], nums[i]); for (int i = n - 2; i \u0026gt;= 0; i--) right[i] = min(right[i + 1], nums[i]); for (int i = 1; i \u0026lt; n - 1; i++) { if (left[i - 1] \u0026lt; nums[i] \u0026amp;\u0026amp; nums[i] \u0026lt; right[i + 1]) ans +=2; else if (nums[i - 1] \u0026lt; nums[i] \u0026amp;\u0026amp; nums[i] \u0026lt; nums[i + 1]) ans++; } return ans; } }; C.","title":"weekly-contest-259"},{"content":"第61次双周赛 A: 差的绝对值为 K 的数对数目  时间复杂度:$O(n)$ 空间复杂度:$O(n)$  class Solution { public: int countKDifference(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { map\u0026lt;int, int\u0026gt; m; int ans; for (auto \u0026amp;\u0026amp; x : nums) { ans += (m[x + k] + m[x - k]); m[x]++; } return ans; } }; B: 从双倍数组中还原原数组 两个关键点: 1. 元素个数一定为偶数 2. 结果数组元素个数一定是原数组二分之一\n 时间复杂度: 排序: $O(nlgn)$ 遍历: $O(n)$ 空间复杂度: $O(n)$  class Solution { public: vector\u0026lt;int\u0026gt; findOriginalArray(vector\u0026lt;int\u0026gt;\u0026amp; changed) { auto n = changed.size(); if (n \u0026amp; 1) return {}; sort(changed.begin(), changed.end()); vector\u0026lt;int\u0026gt; ans; unordered_map\u0026lt;int, int\u0026gt; mp; for (auto \u0026amp;\u0026amp; x : changed) { if (mp[x] == 0) { ans.push_back(x); mp[x * 2]++; }else { mp[x]--; } } if (ans.size() != (n \u0026gt;\u0026gt; 1)) return {}; return ans; } }; C: 租车的最大盈利 动态规划, 类似背包问题,但要注意这是个区间,每次都要更新区间中的值.\n 时间复杂度: $O(n * m)$ 空间复杂度: $O(n)$  class Solution { using LL = long long; public: long long maxTaxiEarnings(int n, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; rides) { sort(begin(rides), end(rides)); vector\u0026lt;LL\u0026gt; dp(n + 1); int i = 0; LL ans = 0; for (auto \u0026amp;\u0026amp; ride: rides) { for ( ; i \u0026lt; ride[0]; i++) { dp[i + 1] = max(dp[i + 1], dp[i]); } dp[ride[1]] = max(dp[ride[1]], dp[ride[0]] + ride[1] - ride[0] + ride[2]); } for (; i \u0026lt; n; i++) { dp[i+1] = max(dp[i], dp[i+1]); } for (auto \u0026amp;\u0026amp; x : dp) { ans = max(ans, x); } return ans; } }; D. 使数组连续的最少操作数 排序 + 二分搜索. 重复元素是一定需要操作的,因此排序后去重,记录新的长度m. 对于任意的$i \u0026lt; m $,通过二分查找找到第一个大于$nums[i] + n - 1$的值. 区间[left, right]中的值即为不需要操作的值,区间外的值都需要操作.\n 时间复杂度: $O(nlgn)$ 空间复杂度: $O(1)$  class Solution { public: int minOperations(vector\u0026lt;int\u0026gt;\u0026amp; nums) { sort(begin(nums), end(nums)); int n = nums.size(); int m = remove_duplicate(nums); int ans = n; int r = 0; for (int i = 0; i \u0026lt; m; i++) { r = binary_search(nums, i, m, n - 1 + nums[i]); // cout \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl;  ans = min(ans, n - (r - i)); } return ans; } int remove_duplicate(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int i = 0; int n = nums.size(); for (int j = 0; j \u0026lt; n; j++) { if (nums[j] == nums[i]) continue; nums[++i] = nums[j]; } return i + 1; } int binary_search(vector\u0026lt;int\u0026gt;\u0026amp; nums, int left, int right, int target) { // cout \u0026lt;\u0026lt; \u0026#34;[\u0026#34; \u0026lt;\u0026lt; left \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; right \u0026lt;\u0026lt; \u0026#34;] target=\u0026#34; \u0026lt;\u0026lt; target \u0026lt;\u0026lt; endl;  while (left \u0026lt; right) { int mid = ((right - left) \u0026gt;\u0026gt; 1) + left; if (nums[mid] \u0026lt; target) { left = mid + 1; }else if (nums[mid] == target) { return mid + 1; }else { right = mid; } } return left; } }; ","permalink":"https://zhangyh.me/posts/leetcode/biweekly-contest-61/","summary":"第61次双周赛 A: 差的绝对值为 K 的数对数目  时间复杂度:$O(n)$ 空间复杂度:$O(n)$  class Solution { public: int countKDifference(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { map\u0026lt;int, int\u0026gt; m; int ans; for (auto \u0026amp;\u0026amp; x : nums) { ans += (m[x + k] + m[x - k]); m[x]++; } return ans; } }; B: 从双倍数组中还原原数组 两个关键点: 1. 元素个数一定为偶数 2. 结果数组元素个数一定是原数组二分之一\n 时间复杂度: 排序: $O(nlgn)$ 遍历: $O(n)$ 空间复杂度: $O(n)$  class Solution { public: vector\u0026lt;int\u0026gt; findOriginalArray(vector\u0026lt;int\u0026gt;\u0026amp; changed) { auto n = changed.","title":"biweekly-contest-61"},{"content":"1 Introduction 本文是《The Google File System》的学习笔记\n2 Design Overview 2.1 Assumptions GFS基于以下基本假设作为设计原则。\n 廉价商用机器出故障是常态 主要存储大文件，通常大于100MB，没有针对小文件的优化 读操作：大规模的流式读、小规模的随机读 写操作：大规模的append写操作、小规模的随机写效率低 支持多个客户端并行 append 到同一个文件 持续的高带宽比低时延重要  2.2 Interface  未实现POSIX API 支持常见文件操作，包括create, delete, open, close, read, write. 包括 snapshot 和 record append  2.3 Architecture  集群通常包括一个 master、多个 chunkserver 和多个访问的 client 文件使用固定大小(64 MB)的 chunk 存储，使用globally unique、immutable的 64bit chunk handle表示 master 维护整个集群所有的 metadata ，通过 heartbeat 与 chunkserve 进行 instruct、state-collect client 以 lib 的形式嵌入到应用中，以供 application 调用 client 和 chunkserver 都不 cache file data，但 client 会 cache metadata  2.4 Single Master  单 mater 简化了设计，但有成为 bottleneck 的风险 client 会缓存 metadata，从而减少和 master 的通信  2.5 Chunk Size chunk size is one of the key design parameters 大 chunk size 的advantages\n 减少 client 和 master 之间对于 metadata 通信 client 对 chunkserver 的某一 chunk 进行操作时，通过 tcp 持久连接减少网络负载 减少了 metadata 在 master 存储的大小 大 chunk size 的 disadvantages 对于小文件产生的 chunk 少，多个 client 的时可能会形成 hot spot。 但目前来看不是主要问题  2.6 Metadata 有三种主要类型的 metadata\n file and namespace file -\u0026gt; chunk handle chunk handle -\u0026gt; locations of each replica   metadata 全部存储在 master 的内存中 1和2会以 operation log 的形式持久化到磁盘和远端机器中 3不持久化到磁盘中，master 启动的时候会和所有的 chunkserver 通信来获取3，之后在运行中通过 heartbeat 来维护  2.6.1 In-Memory Data Structures 全内存有利于进行快速的 scan，通过 scan 我们能够完成以下操作。\n chunk garbage collection (参考section 4.4.2) chunkerserver 故障时的 chunk 再复制 在 chunkserver 间的 chunk 迁移，用来平衡负载和磁盘使用率  全内存导致chunk的数量受限于 master 内存的大小，但作者有以下的考量\n 64 bit 即可管理一个 64MB 的 chunk 大部分 chunk 都是满的 ( full ) 单纯增加内存的开销比较低 (与增加整个系统的复杂度相比)  2.6.2 Chunk Locations chunk location 信息由 chunkserver 来维护，master 通过 hearbeat 通信来获取，并存放到 metadata 中\n但 chunk locations 并不永久存放在 master 中，参考 section 2.6\n简化了 chunkserver 加入、退出、更名、故障、重启的时候，master 与 chunkserver 同步的问题\n2.6.3 Operation Log  日志记录了重要的 metadata 的变动, 被持久化到本地和多台远程机器上 只有当日志持久化成功时，才会认为整个操作完成，返回成功给客户端 为了加快 master 的启动，会设置 checkpoint，checkpoint 以 b树 存储，可以直接映射到 master 内存中 master 通过最新的 checkpoint 和 checkpoint 之后的日志来进行数据恢复  2.7 Consistency Model GFS采用较宽松的一致性模型\n2.7.1 Guarantee by GFS  文件命名空间的改动是原子的 namespace lock 保证了原子性和正确性 section 4.1  一致性模型的定义\n定义：\n consistent：如果所有客户端无论从哪个副本读，读到的数据都是一样的，那么就认为这个数据是一致的。 defined：修改文件之后，相关数据是一致的，并且客户端能够读取到它刚才修改的内容，那么相关数据是已定义的。已定义暗含了一致。  GFS 提供一个弱一致性模型。对于并发随机写入操作来说，数据是一致的，但是未定义的。对于追加写入操作来说，客户端总是可以读取到一致并且已定义的数据，但是实际储存在各个 chunk 服务器上的数据可能有部分是不一致的。\n2.7.2 Implications of Applications GFS 通过以下几点保证数据一致性：\n 对 chunk 的所有副本修改操作顺序一致。 使用 chunk 版本号来检测副本因为服务器宕机而失效。 与服务器定期握手来找到失效的 chunk 服务器。 使用 checksum 来校验数据是否损坏。  3 System Interactions 原则：最小化所有操作与master的交互\n3.1 Leases and Mutation Order  多个 replica 中只有一个获得 lease，因此只有一个 primary，其余为 secondary 由 primary 决定 chunk 变更的顺序，secondary 按照 primary 的要求，按照指定顺序进行变更 lease 默认有 60s 的租期，同一时刻只有一台 primary 持有 lease\n  写入流程\n client 向 master 询问持有 chunk 租约的 chunkserver 以及 chunk 其它副本的位置。 如果没有，master 选择chunk 的一个副本建立租约 master 将主 chunkserver 的标识和其它副本的位置返回给 client，client 进行缓存 client 将数据推送到所有副本。chunkserver 将数据保存在内部的 LRU 缓存，此时并没有写入磁盘 一旦所有副本回复已经收到数据，client 向 primary 发送写请求。primary 向接收到的所有操作分配连续的序列号，操作可能来自不同 client primary 把写请求发送给所有 secondary，secondary 按照主副本分配的序列号以相同的顺序执行 secondary 向主副本回复完成操作 primary 回复 client。任何副本的 error 都会返回，client 重新执行 3-7 的操作  3.2 Data Flow  data flow 与 control flow 分离，提高网络效率 使用 chain 式的发送，而不是 tree 式，从而充分利用每台机器的带宽，避免瓶颈 尽量选择没有接受数据且离自己最近的机器发送数据，通过 ip address 来估计机器之间的距离 采用 tcp 来发送数据  3.3 Atomic Record Appends  GFS 保证追加记录的原子性。当存在多个并发的追加记录时，GFS 对于每个追加记录至少有一次是写入成功的。GFS 指定写入的 offset 并且在之后返回，所有副本中的 offset 是一致的。 追加记录在之前描述的控制流程之上加了一些额外的步骤。对于一次指定的追加记录来说，主 chunk 服务器会检查给定 chunk 的大小。如果追加记录使得这个 chunk 的大小超过限制，服务器会填充这个 chunk 到最大大小然后指示客户端发起请求写入下一个 chunk。 如果追加记录在任意一个 chunk 服务器失败了，客户端需要进行重新操作。重新操作的结果是，同一个 chunk 的副本可能拥有不一致的记录。GFS 不保证所有副本在字节序上是完全一致的，但至少保证有一次成功的写入。 因此，追加记录将使数据是一致的，但可能包含部分不一致的局部数据，如填充和错误。  3.4 Snapshot copy-on-write\n snapshot 前，首先收回相关 chunk 的 lease，这保证了需要修改 chunk 时，首先要和 master 交互，从而在修改之前进行复制 master 维持一个对所有 chunk 的引用计数。当客户端发起一次快照请求时，并不实际进行复制，而是将相应引用计数加一。当对相应服务器发起写入请求时，master 注意到它的引用计数大于一，然后才复制一个新的 chunk，并指示客户端写入这个新 chunk。引用计数减一  4. Master Operation 4.1 Namespace Management and Locking  GFS 的名称空间是一个全局路径和元数据映射关系的查找表。这个表使用前缀压缩储存在内存中。在名称空间的属性结构上，每个节点都是都有一个关联的读写锁。 每一个master操作在执行前，都需要获取锁。假设我们要操作 /d1/d2/\u0026hellip;/dn/leaf,需要先获取 /d1, /d1/d2, \u0026hellip;,/d1/d2/\u0026hellip;/dn的读锁，在获取 /d1/d2/\u0026hellip;/dn/leaf 的写锁或读锁  4.2 Replica Placement 副本放置的两个主要原则：\n 最大化数据的可靠性和可用性 最大化网络带宽的利用率  4.3 Creation, Re-replication, Rebalancing chunk被创建通常处于三种目的creation, re-replication, rebalancing\nchunk creation 存放位置, 按优先级考虑以下三种因素：\n chunkserver 的磁盘使用率（与平均水平相比） chunkserver 上最近创建 chunk 的数量 chunkserver 的地理位置分布（是否在一个 rack 上）  当副本数量低于用户指定的水平是，会进行副本的 re-replication\n优先考虑以下的 chunk 进行 re-replication\n 优先复制总数量更少的 chunk 优先复制活跃的 chunk 优先复制阻塞 client 流程的 chunk  会定期进行 chunk 的 rebalancing，是每台 chunkserver 都拥有大致相同的磁盘使用水平，以充分利用磁盘\n4.4 Garbage Collection 惰性的垃圾回收，使得整个系统更为简单\n4.4.1 Mechanism 文件删除流程\n 记录删除操作的 log 将文件 rename 成为一个包含时间戳信息的隐藏的名字 master 对 metadata 进行 scan 时，删除3天前被删除文件的元数据 （也就是三天内可以对文件进行恢复，这个时间是可以配置的） master 通过与 chunkserver 通信，彻底删除磁盘上的文件  4.4.2 Discussion GFS的垃圾回收较为容易，通过 file-\u0026gt;arrays of chunk handles 的映射找出所有未被使用的 chunk， 通过 delay delete 的方式删除（即4.4.1所说）\nadvantages:\n 在大规模系统中简单可靠， 多个删除操作在 master 较为空闲时进行后台批操作，分散开销 delay delete 为错误删除提供了安全保障  disadvantages:\n delay delete 在磁盘空间紧张时阻碍了用户的使用 对于重复进行 create 和 delete 的应用不能马上释放资源（GFS可以配置指定目录下的文件删除策略——如即时删除、无副本）  4.5 Stale Replica Detection  每一个chunk，在master中都维护了一个 version number，同时 chunkserver 中也记录了当前的 version master 与 chunk 签订租约时增加版本号，然后通知副本( Replica ) master 在垃圾回收的过程中移除过期失效的版本，在平时的读写操作中不会考虑过期版本  5. Fault Tolerance and diagnosis 最大挑战之一：频繁的组件故障\n5.1 High Availablity 保证高可用的两个策略：fast recovery 和 replication.\n5.1.1 Fast Recovery  数秒内恢复 不区分异常关闭和正常关闭  5.1.2 Chunk Replication  可以为不同的 namespace 设置不同的复制等级，默认为3 奇偶校验和纠删码 其他的冗余方案  5.1.3 Master Replication  master 所有操作日志和 checkpoint 备份在多个机器上 每个操作只有在写入磁盘和多个 master 备份后，才算生效 master 启动备用机器，通过 dns 别名的方式更改 client 指向为对 master 备用机的访问 影子 master 提供只读服务，通常由几秒分之一的滞后，通常体现在 metadata 上  5.2 Data Integrity  chunkserver 使用 checksum 来检查数据完整性 每个 chunk 分为 64KB 的 block，每个 block 对应一个 32 位的 checksum 读操作时检查 checksum 是否正确, 错误时返回 client 错误信息, 通知 master，从其它副本恢复数据 checksum 效验不需要额外 IO，对性能影响小 checksum 对 chunk 追加写入操作做了优化，只增量更新最后一个不完整 block 的 checksum chunkserver 空闲时扫描和校验不活动的 chunk  参考链接  MIT 6.824（二）GFS的一致性模型  ","permalink":"https://zhangyh.me/posts/paper/aug/gfs/","summary":"1 Introduction 本文是《The Google File System》的学习笔记\n2 Design Overview 2.1 Assumptions GFS基于以下基本假设作为设计原则。\n 廉价商用机器出故障是常态 主要存储大文件，通常大于100MB，没有针对小文件的优化 读操作：大规模的流式读、小规模的随机读 写操作：大规模的append写操作、小规模的随机写效率低 支持多个客户端并行 append 到同一个文件 持续的高带宽比低时延重要  2.2 Interface  未实现POSIX API 支持常见文件操作，包括create, delete, open, close, read, write. 包括 snapshot 和 record append  2.3 Architecture  集群通常包括一个 master、多个 chunkserver 和多个访问的 client 文件使用固定大小(64 MB)的 chunk 存储，使用globally unique、immutable的 64bit chunk handle表示 master 维护整个集群所有的 metadata ，通过 heartbeat 与 chunkserve 进行 instruct、state-collect client 以 lib 的形式嵌入到应用中，以供 application 调用 client 和 chunkserver 都不 cache file data，但 client 会 cache metadata  2.","title":"The Google File System"},{"content":"为什么需要内存对齐？ 首先需要从物理硬件上了解计算机如何进行内存访问的。\n Channel \u0026gt; DIMM \u0026gt; Rank \u0026gt; Chip \u0026gt; Bank \u0026gt; Coloum/Row \u0026gt; Cell\n 如上图 CPU包括两个Channel 每个Channel包括两个DIMM 每个DIMM由Rank组成 Rank由8个内存颗粒chip组成 每个Chip包括8个Bank\nCPU读取内存时从8个chip中每个读取8bit字节，从而构成64bit column和row定位的一个单元格cell中有8个bit\n因此一次性最少读取64bit，这恰好也是cacheline的大小。 （cacheline是cache的基本单位，每个cache由若干cacheline组成）\n什么是内存对齐 从上面我们可以知道，一次性最少读取8B，这也是局部性原理的一种使用。\n内存对齐就是代码编译后在内存中的布局，当一个内存地址刚好能够整除8，就称为其内存地址是8字节对齐的。\n为什么需要内存对齐 对于go中定义的如下结构\ntype Type1 struct { a int8 b int64 c int32 } 其内存布局是这样的： 通过unsafe.Sizeof()可以打印出该结构占用了24字节的内存。\n如果调整一下顺序：\ntype Type2 struct { a int8 c int32 b int64 } 便可以节约一个字节的内存\n零大小字段 如果结构体或数组类型不包含大小大于零的字段或元素，那么它的大小就为0\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type M struct { m int64 x struct{} } type N struct { x struct{} n int64 } func main() { m, n := M{}, N{} fmt.Println(unsafe.Sizeof(m)) // 16 \tfmt.Println(unsafe.Sizeof(n)) // 8 } 为什么只是把零字段放到struct M的最后面就会导致增加了一个字节。\n原因是如果我们不额外分配一个字节的内存，那么零字段对应的地址指针就不属于struct管理的范围，就指向了一个非法的地址，成为了野指针。\nReferences  https://zhuanlan.zhihu.com/p/355158723 https://zhuanlan.zhihu.com/p/26327347 https://www.derror.com/p/memory-physical-structure/  ","permalink":"https://zhangyh.me/posts/misc/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/","summary":"为什么需要内存对齐？ 首先需要从物理硬件上了解计算机如何进行内存访问的。\n Channel \u0026gt; DIMM \u0026gt; Rank \u0026gt; Chip \u0026gt; Bank \u0026gt; Coloum/Row \u0026gt; Cell\n 如上图 CPU包括两个Channel 每个Channel包括两个DIMM 每个DIMM由Rank组成 Rank由8个内存颗粒chip组成 每个Chip包括8个Bank\nCPU读取内存时从8个chip中每个读取8bit字节，从而构成64bit column和row定位的一个单元格cell中有8个bit\n因此一次性最少读取64bit，这恰好也是cacheline的大小。 （cacheline是cache的基本单位，每个cache由若干cacheline组成）\n什么是内存对齐 从上面我们可以知道，一次性最少读取8B，这也是局部性原理的一种使用。\n内存对齐就是代码编译后在内存中的布局，当一个内存地址刚好能够整除8，就称为其内存地址是8字节对齐的。\n为什么需要内存对齐 对于go中定义的如下结构\ntype Type1 struct { a int8 b int64 c int32 } 其内存布局是这样的： 通过unsafe.Sizeof()可以打印出该结构占用了24字节的内存。\n如果调整一下顺序：\ntype Type2 struct { a int8 c int32 b int64 } 便可以节约一个字节的内存\n零大小字段 如果结构体或数组类型不包含大小大于零的字段或元素，那么它的大小就为0\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type M struct { m int64 x struct{} } type N struct { x struct{} n int64 } func main() { m, n := M{}, N{} fmt.","title":"聊聊内存对齐"},{"content":" paper原文：LSM-based storage techniques: a survey\n LSM-tree basics 对于索引结构通常有两种更新策略，即in-place update和out-of-place update。\nin-place通常使用B+树作为底层数据结构，通过随机写来更新数据项，带来的是读数据的优化，同时每个数据项只存有一份，因此节约了空间。\nout-place通常使用lsm tree作为底层数据结构，将随机写转化为顺序写，加快了写的速度，但同时降低了读数据的性能，另外，对同一个key，存有多个版本，带来了空间上的浪费。\nLevelDB是谷歌开源的kv数据库，它基于内存-磁盘的存储层次，实现了LSM Tree最基本的功能。 内存中有memtable，使用skiplist来按顺序存储kv对 磁盘中有分层的sstable，使用sorted-string table以文件的形式来存储。 sstable包括了data block、index block、footer block\n如今的lsm tree通常为了加快读速度，往往会具有bloom filter组件，该组件有两个操作：插入key和检查key是否存在。为磁盘中的每一level，维护一个bloom filter，从而提高读性能。需要注意，它是false positive的。 同时因为该结构比较小，往往把他缓存到内存当中。\n对于failure recovery，使用WAL保证内存中memtable的recovery，使用manifest保证merge过程中sstable的recovery。\n有两种常用的merge policy，如上图所示。 Leveling merge policy，要求每一层的SSTable之间不能overlap，merge的时候将第i层的SSTable和第i+1层overlape的所有SSTables进行merge，然后写入i+1层。也就是说通过leveling通过频繁的merge，使得每一层全部有序，牺牲部分写性能来换取读性能。\nTiering merge policy，要求每一层的SSTable之间可以overlap，在sstable达到一定的数量或者size要求后，对该层所有的SSTable进行merge sort，然后直接flush进下一层。该策略通过减少merge操作，牺牲部分读性能换取了写性能。\nLSM-tree improvement 文章将对LSM-tree的优化分为以下几个方面：\n Write Amplification: out-of-place数据结构所具有的问题，降低了写性能和磁盘寿命。 Merge Operation: merge后会造成buffer cache miss，大数据量的merge会造成write stall Hardware: 针对large memory,multi-core, SSD/NVM, native storage的优化 Special Workloads: Auto-tuning: 不可能同时达到read,write,space同时最优，并且由于lsm tree拥有大量参数，手动调优也是困难的。 Secondary Indexing: lsm tree只支持简单的kv接口，二级索引也是一个方向。  ","permalink":"https://zhangyh.me/posts/paper/aug/suvery-of-lsm/","summary":" paper原文：LSM-based storage techniques: a survey\n LSM-tree basics 对于索引结构通常有两种更新策略，即in-place update和out-of-place update。\nin-place通常使用B+树作为底层数据结构，通过随机写来更新数据项，带来的是读数据的优化，同时每个数据项只存有一份，因此节约了空间。\nout-place通常使用lsm tree作为底层数据结构，将随机写转化为顺序写，加快了写的速度，但同时降低了读数据的性能，另外，对同一个key，存有多个版本，带来了空间上的浪费。\nLevelDB是谷歌开源的kv数据库，它基于内存-磁盘的存储层次，实现了LSM Tree最基本的功能。 内存中有memtable，使用skiplist来按顺序存储kv对 磁盘中有分层的sstable，使用sorted-string table以文件的形式来存储。 sstable包括了data block、index block、footer block\n如今的lsm tree通常为了加快读速度，往往会具有bloom filter组件，该组件有两个操作：插入key和检查key是否存在。为磁盘中的每一level，维护一个bloom filter，从而提高读性能。需要注意，它是false positive的。 同时因为该结构比较小，往往把他缓存到内存当中。\n对于failure recovery，使用WAL保证内存中memtable的recovery，使用manifest保证merge过程中sstable的recovery。\n有两种常用的merge policy，如上图所示。 Leveling merge policy，要求每一层的SSTable之间不能overlap，merge的时候将第i层的SSTable和第i+1层overlape的所有SSTables进行merge，然后写入i+1层。也就是说通过leveling通过频繁的merge，使得每一层全部有序，牺牲部分写性能来换取读性能。\nTiering merge policy，要求每一层的SSTable之间可以overlap，在sstable达到一定的数量或者size要求后，对该层所有的SSTable进行merge sort，然后直接flush进下一层。该策略通过减少merge操作，牺牲部分读性能换取了写性能。\nLSM-tree improvement 文章将对LSM-tree的优化分为以下几个方面：\n Write Amplification: out-of-place数据结构所具有的问题，降低了写性能和磁盘寿命。 Merge Operation: merge后会造成buffer cache miss，大数据量的merge会造成write stall Hardware: 针对large memory,multi-core, SSD/NVM, native storage的优化 Special Workloads: Auto-tuning: 不可能同时达到read,write,space同时最优，并且由于lsm tree拥有大量参数，手动调优也是困难的。 Secondary Indexing: lsm tree只支持简单的kv接口，二级索引也是一个方向。  ","title":"LSM-based storage techniques: a survey"},{"content":"WiscKey Design Goals  Low写放大 Low读放大 SSD优化 Feature-rich API (scan、snapshot) Realistic k-v size (value的size通常比key的大很多)  K-V Separation  LSM tree的主要性能成本在于Compaction，但它维护了key的有序性，对于加速读也是十分有必要的。 Compaction只需要对key排序，因此考虑将k-v分开存储。只把value的地址和key放在一起。  LSM tree的size将大大变小，减少了写放大。 读操作虽然需要一次额外的寻址操作，但更小的LSM tree加快了检索同时更容易缓存到大内存中。    Challenge   Parallel Range Query 在levelDB中，范围查询通过iterator的顺序读实现，但是现在由于和key一同存储的只有value的地址，范围查询变为了随机io。 我们在读取所有的地址后，写入一个队列，通过多线程并发读取，来加快范围查询的性能。\n  Garbage Collection 由于把所有的数据都存到了vLog里，最朴素的垃圾回收的方法当然是扫描一遍LSM-tree，但开销太大了，只适用于离线环境。 WiscKey在vlog中存储(ksize, vsize, key, value)，并维护head和tail指针。   数据在head处添加 垃圾回收线程从tail处扫描，每次扫描一定量的数据（几MB），然后在LSM-tree中查找，如果kv对有效的话，则再把它添加到head处。 因此，只有tail和head之间的数据是有效的。\nCrash Consistency  Optimizations  Value-Log Write Buffer  对于写密集的数据集，频繁的大量的小size的value写入，会导致较大的系统开销。 因此考虑在内存中维护Buffer。 当读数据的时候，先到vlog write buffer中查找，如果没有，再查vlog。 crash-consistency的维护类似于levelDB，使用WAL。\nOptimizing the LSM-tree Log  在写LSM-tree之前需要先写vlog，因为这里我们加了vlog write buffer，所以我们直接用vlog的日志作为WAL。\n","permalink":"https://zhangyh.me/posts/paper/aug/wisckey/","summary":"WiscKey Design Goals  Low写放大 Low读放大 SSD优化 Feature-rich API (scan、snapshot) Realistic k-v size (value的size通常比key的大很多)  K-V Separation  LSM tree的主要性能成本在于Compaction，但它维护了key的有序性，对于加速读也是十分有必要的。 Compaction只需要对key排序，因此考虑将k-v分开存储。只把value的地址和key放在一起。  LSM tree的size将大大变小，减少了写放大。 读操作虽然需要一次额外的寻址操作，但更小的LSM tree加快了检索同时更容易缓存到大内存中。    Challenge   Parallel Range Query 在levelDB中，范围查询通过iterator的顺序读实现，但是现在由于和key一同存储的只有value的地址，范围查询变为了随机io。 我们在读取所有的地址后，写入一个队列，通过多线程并发读取，来加快范围查询的性能。\n  Garbage Collection 由于把所有的数据都存到了vLog里，最朴素的垃圾回收的方法当然是扫描一遍LSM-tree，但开销太大了，只适用于离线环境。 WiscKey在vlog中存储(ksize, vsize, key, value)，并维护head和tail指针。   数据在head处添加 垃圾回收线程从tail处扫描，每次扫描一定量的数据（几MB），然后在LSM-tree中查找，如果kv对有效的话，则再把它添加到head处。 因此，只有tail和head之间的数据是有效的。\nCrash Consistency  Optimizations  Value-Log Write Buffer  对于写密集的数据集，频繁的大量的小size的value写入，会导致较大的系统开销。 因此考虑在内存中维护Buffer。 当读数据的时候，先到vlog write buffer中查找，如果没有，再查vlog。 crash-consistency的维护类似于levelDB，使用WAL。\nOptimizing the LSM-tree Log  在写LSM-tree之前需要先写vlog，因为这里我们加了vlog write buffer，所以我们直接用vlog的日志作为WAL。","title":"Wisckey: Separating keys from values in ssd-conscious storage"},{"content":"Hashkv: Enabling efficient updates in KV storage via hashing Introduction kv分离的Wisckey在vLog的GC上有着以下的问题：\n 最新写入的数据被从tail迁移到head处，带来了写放大。 每次GC，对于每一项都需要去查询LSM-Tree，去验证是否还有效，造成大量随机读  Design Storage Management 固定大小的空间单元main segment和log segment。 默认分别为64MB和1MB.\nsegment group 包括一个main segment和多个log segment.\n内存中全局的segment table存储每一个segment group接下来插入或更新的位置。\n为了方便GC，segment group存储了key/value size，key，value\nGC Collection GC以segment group为单元，当free log segment用尽的时候会触发。\n 首先选择候选的segment group，并识别valid KV 然后将valid KV写新的main segment和log segment 再释放之前未使用的log segment 最后更新LSM-Tree中value的最新位置  两个问题：\n 如何选择候选的segment group? 根据更新的kv数量，快速选择 如何快速验证KV时valid的 从尾部第一次读到的key，它对应的kv一定是最新的。  Hotness Awareness 在对segment group进行GC后，决定其中数据项为hot还是code。\nhot数据仍然写回segment group. code数据写到另外一个区域，旨在segment group中保留其metadata()\n如何判断冷热？ 在最后插入后，又更新过一次的即为热数据。\n我们称呼该过程为tagging，注意，tagging只发生在GC时。\nSelective KV Seperation 对于size较大的kv，进行另外的value store 而对于较小的kv，就直接存储到LSM-tree中\nRange Scan read-ahead 预读\n","permalink":"https://zhangyh.me/topics/paper/hashkv.html","summary":"Hashkv: Enabling efficient updates in KV storage via hashing Introduction kv分离的Wisckey在vLog的GC上有着以下的问题：\n 最新写入的数据被从tail迁移到head处，带来了写放大。 每次GC，对于每一项都需要去查询LSM-Tree，去验证是否还有效，造成大量随机读  Design Storage Management 固定大小的空间单元main segment和log segment。 默认分别为64MB和1MB.\nsegment group 包括一个main segment和多个log segment.\n内存中全局的segment table存储每一个segment group接下来插入或更新的位置。\n为了方便GC，segment group存储了key/value size，key，value\nGC Collection GC以segment group为单元，当free log segment用尽的时候会触发。\n 首先选择候选的segment group，并识别valid KV 然后将valid KV写新的main segment和log segment 再释放之前未使用的log segment 最后更新LSM-Tree中value的最新位置  两个问题：\n 如何选择候选的segment group? 根据更新的kv数量，快速选择 如何快速验证KV时valid的 从尾部第一次读到的key，它对应的kv一定是最新的。  Hotness Awareness 在对segment group进行GC后，决定其中数据项为hot还是code。\nhot数据仍然写回segment group. code数据写到另外一个区域，旨在segment group中保留其metadata()\n如何判断冷热？ 在最后插入后，又更新过一次的即为热数据。\n我们称呼该过程为tagging，注意，tagging只发生在GC时。","title":"Hashkv: Enabling efficient updates in KV storage via hashing"},{"content":"A Light-weight Compaction Tree to Reduce I/O Amplification toward Efficient Key-Value Stores Introduction 一般情况下的LSM Tree写放大能达到50X倍 缓解写放大的方法可能有以下几种：\n 使用更大的内存buffer 利用设备的特性 逐步散列 KV 项 减少level层级 减少每层的空间放大因子  Design light-weight compaction 也是借鉴了wisckey中提到的，merge and sort过程只是面向key的，不需要value的参与 在对Level i 和 Level i+1进行compaction时，我们把第i层的候选的sstable成为victim，把与victim有overlap的i+1层的sstable成为overlaped. (注意该论文为sstable设计了另外一种存储格式，成为DTable) 因此整个lightweight compaction过程为:\n 读取victim到内存中，victim包括了overlaped的metadata 然后根据metadata，将victim分为几个segment 再根据key range将segment追加到对应的DTable中  victim一层的写放大被消除了，随之带来的问题就是DTable的读，虽然每一层的DTable之间是无overlap且有序的，但是DTable内的key值并不是完全有序的。\n降低了大概10X的写放大.\nMetadata Aggregation overlaped的元数据如何获取。 直觉的方法是直接从overlaped读，但这带来的随机io违背了我们的设计初衷。 另一种是直接在内存中缓存元数据，但这部分开销并不算小，并不划算 为了解决这个问题，我们提出了元数据聚合。 在一次compaction完成后，第i+1层被更新的元数据存储到victim中，以此避免下一次compaction时对metadata的访问呢。\n通过compaction过程中一次额外的写，减少AF倍的i+1层的随机读。\nData structure of DTable 每个DTable维护下层的overlaped Dtables metadata 每次compaction过程中append进来的数据作为一个segment,segment之间的key是overlap的,会导致查找性能的下降 MetadaBlock包括了bloom filter blocks,overlaped metada_index block, metada_index block,index block footer\n每个segment有一个sequence number，每次读取时按照降序一次读取segment\nWorkload Balance in DTables 不同的key range很容易导致数据不平衡。因此需要进行数据迁移。\n","permalink":"https://zhangyh.me/posts/paper/aug/lwc-tree/","summary":"A Light-weight Compaction Tree to Reduce I/O Amplification toward Efficient Key-Value Stores Introduction 一般情况下的LSM Tree写放大能达到50X倍 缓解写放大的方法可能有以下几种：\n 使用更大的内存buffer 利用设备的特性 逐步散列 KV 项 减少level层级 减少每层的空间放大因子  Design light-weight compaction 也是借鉴了wisckey中提到的，merge and sort过程只是面向key的，不需要value的参与 在对Level i 和 Level i+1进行compaction时，我们把第i层的候选的sstable成为victim，把与victim有overlap的i+1层的sstable成为overlaped. (注意该论文为sstable设计了另外一种存储格式，成为DTable) 因此整个lightweight compaction过程为:\n 读取victim到内存中，victim包括了overlaped的metadata 然后根据metadata，将victim分为几个segment 再根据key range将segment追加到对应的DTable中  victim一层的写放大被消除了，随之带来的问题就是DTable的读，虽然每一层的DTable之间是无overlap且有序的，但是DTable内的key值并不是完全有序的。\n降低了大概10X的写放大.\nMetadata Aggregation overlaped的元数据如何获取。 直觉的方法是直接从overlaped读，但这带来的随机io违背了我们的设计初衷。 另一种是直接在内存中缓存元数据，但这部分开销并不算小，并不划算 为了解决这个问题，我们提出了元数据聚合。 在一次compaction完成后，第i+1层被更新的元数据存储到victim中，以此避免下一次compaction时对metadata的访问呢。\n通过compaction过程中一次额外的写，减少AF倍的i+1层的随机读。\nData structure of DTable 每个DTable维护下层的overlaped Dtables metadata 每次compaction过程中append进来的数据作为一个segment,segment之间的key是overlap的,会导致查找性能的下降 MetadaBlock包括了bloom filter blocks,overlaped metada_index block, metada_index block,index block footer","title":"A Light-weight Compaction Tree to Reduce I/O Amplification toward Efficient Key-Value Stores"},{"content":"Introduction 过去的很多研究都是基于仿真模拟的NVM，他们基于——NVM表现和DRAM类似，只不过性能相对较低——这样的假设完成了研究。\n但实验发现，Optane DIMM的性能与DRAM相比，更依赖于\n access size access method(read,write) pattern degree of concurrency  本文通过经过实验证明了之前的很多仿真方法都是不可靠的。\nBackground Optane DIMM是第一款商用NVDIMM 与SSD/HDD相比，它low latency、higher read bandwidth、byte-address 与DRAM相比，它higher density、persistent\nOptane Memory Optane DIMM使用和DRAM相同的插槽，和处理器的集成内存控制器（iMC)相连接。Intel Cascade Lake处理器是第一个支持Optane DIMM的处理器，有一个或两个processor die，每个die支持两个iMC，每个iMC支持三个channel，因此一个die可以支持6个Optane DIMM\n为了持久化，iMC维护一个asynchronous DRAM refresh(ADR)区域，写入这个区域内的数据都能保证其被持久化。ADR区域不保证处理器cache的持久化。\niMC按照缓存行粒度(64byte)和Optane DIMM通信。\nOptane DIMM中\n3D-XPoint物理介质的访问粒度为256byte，因此会造成写放大，所以会在XPController中有controller负责将小于256B的操作变成256B的访问，同时内部有Buffer用来合并临近的访问。\n为了磨损均匀、坏块的管理，AIT用于进行内部地址转换。\nOperation Model Optane DIMM有两种模式Memory和App Direct\n Memory Model 该模式下直接将Optane DIMM作为普通的内存使用，将DRAM作为内存的Cache，DRAM是透明的，直接观察到的内存容量就是Optane DIMM的容量。 该模式可以解决一些内存数据库内存容量不足的问题。 App Direct Model 该模式将Optane DIMM作为持久化设备使用，直接通过CPU指令读写。文件系统和其他的管理层管理持久化内存的分配、回收和访问。  支持交错访问，最小的单位是4KB，保证一个page一定是从一个DIMM中读取出来的\nISA Support store: 绕过store buffer ntstore: 绕过CPU cache，直接写到内存。一般用于写完就不管的情况，可以防止污染cache。 clflush: 把cache line刷回内存，并且让cache line失效。只能串行执行。 clflushopt: 功能同clflush，但是不同缓存行可以并发执行。 clwb: 除了写回后不让cache line失效，其他同clflushopt。 sfence：写屏障，在sfence指令前的写操作当必须在sfence指令后的写操作前完成\nPerformance Characterization Typical Latency Optane的读延迟是DRAM的2-3倍。作者把都延迟归因于物理介质本身。 Optane随机读写和序列读写之间的差异有80%，DRAM只有20%。作者认为是因为XPBuffer导致顺序读更加快。\nBest Practices for Optane DIMM 之前的仿真模拟根本无法捕捉到Optane行为的细节，优化disk和memory软件的传统经验不适用于Optane。\n本文基于实验提出了使用于Optane DIMM的Best Practices\n Avoid random accesses smaller than \u0026lt; 256 B. 避免小于 256 字节的随机读写。 Use non-temporal stores when possible for large transfers, and control of cache evictions. 大内存操作时，使用 ntstore 指令绕过 CPU Cache。 Limit the number of concurrent threads accessing a 3D XPoint DIMM. 限制一个 Optane DIMMs 通道的并发数。 Avoid NUMA accesses (especially read-modify-write sequences). 避免 NUMA 访问。其实内存也一样，远端内存比本地内存要慢不少，这个问题在 Optane DIMMs 表现更突出，需要特别注意。  Aovid small random access 实验证明Optane DIMM中的cache大小大概为16KB，同时读的时候也会竞争这部分的空间。\n避免小于256字节的随机读写。 如果不可避免地话，应该限制工作集大小不应超过16KB，以充分利用locality。\n","permalink":"https://zhangyh.me/posts/paper/aug/optane/","summary":"Introduction 过去的很多研究都是基于仿真模拟的NVM，他们基于——NVM表现和DRAM类似，只不过性能相对较低——这样的假设完成了研究。\n但实验发现，Optane DIMM的性能与DRAM相比，更依赖于\n access size access method(read,write) pattern degree of concurrency  本文通过经过实验证明了之前的很多仿真方法都是不可靠的。\nBackground Optane DIMM是第一款商用NVDIMM 与SSD/HDD相比，它low latency、higher read bandwidth、byte-address 与DRAM相比，它higher density、persistent\nOptane Memory Optane DIMM使用和DRAM相同的插槽，和处理器的集成内存控制器（iMC)相连接。Intel Cascade Lake处理器是第一个支持Optane DIMM的处理器，有一个或两个processor die，每个die支持两个iMC，每个iMC支持三个channel，因此一个die可以支持6个Optane DIMM\n为了持久化，iMC维护一个asynchronous DRAM refresh(ADR)区域，写入这个区域内的数据都能保证其被持久化。ADR区域不保证处理器cache的持久化。\niMC按照缓存行粒度(64byte)和Optane DIMM通信。\nOptane DIMM中\n3D-XPoint物理介质的访问粒度为256byte，因此会造成写放大，所以会在XPController中有controller负责将小于256B的操作变成256B的访问，同时内部有Buffer用来合并临近的访问。\n为了磨损均匀、坏块的管理，AIT用于进行内部地址转换。\nOperation Model Optane DIMM有两种模式Memory和App Direct\n Memory Model 该模式下直接将Optane DIMM作为普通的内存使用，将DRAM作为内存的Cache，DRAM是透明的，直接观察到的内存容量就是Optane DIMM的容量。 该模式可以解决一些内存数据库内存容量不足的问题。 App Direct Model 该模式将Optane DIMM作为持久化设备使用，直接通过CPU指令读写。文件系统和其他的管理层管理持久化内存的分配、回收和访问。  支持交错访问，最小的单位是4KB，保证一个page一定是从一个DIMM中读取出来的\nISA Support store: 绕过store buffer ntstore: 绕过CPU cache，直接写到内存。一般用于写完就不管的情况，可以防止污染cache。 clflush: 把cache line刷回内存，并且让cache line失效。只能串行执行。 clflushopt: 功能同clflush，但是不同缓存行可以并发执行。 clwb: 除了写回后不让cache line失效，其他同clflushopt。 sfence：写屏障，在sfence指令前的写操作当必须在sfence指令后的写操作前完成","title":"An Empirical Guide to the Behavior and Use of Scalable Persistent Memory"},{"content":"Introduction 和目前的存储技术（例如flash、硬盘）相比， NVM有着以下的没有被LSM考虑的优点：\n 对于持久存储的随机访问的高性能 in-place update的低成本 (具体是?) 低时延、高带宽为application-level的并行化提供了机会  作者认为探索redesign适用于NVM的LSM是有意义的，而不是design a new data structure。 基于以下考量：\n 未来几年NVM和SSD共存，形成异质存储，而不是完全取代。redesign LSM可以在利用NVM的优点的前提下，同时不失去ssd和硬盘最优化的优势。 redesign lsm能为现有的应用提供向后兼容 保证批量写入NVM同样重要（NVM写延迟为DRAM的5-10倍）  Motivation 单纯的硬件NVM的读写是SSD的100倍左右，但在LevelDB在NVM和SSD上的差异只有4-7倍 因此可以说目前的LSM没有充分利用NVM的硬件优势，软件开销较大\nInsert Latency insert latency来源有三个方面：\n WAL memtable insert compaction   对于compaction 内存中的mutable memtable在写满之后会刷新成immutable memtable，由后台进程将其压缩进磁盘，同时新开一个mutable memtable，来接管写入 问题是新的mutable memtable写满之后，如果immutable memtable还没有刷到磁盘内，就会造成系统的停顿 当进行大量的写入时，这会成为insert latency的主要来源。\n 可能会说，让memtable大一点不就可以解决，但这会带来一系列的问题：\n 增大memtable会带来双倍的内存占用，因为mutable memtable和immutable memtable需要同时增大 WAL的磁盘占用也会更大，因为他需要容纳更多的指令 LSM为了性能并不commit log。   Third, LSMs suchas LevelDB and RocksDB do not enforce commits (sync) when writing to a log; as a result, an application crash or power-failure could lead to data loss\n log更大导致故障恢复的时间更慢   Finally, the cost of checksumming and logging also increases\n   Read Latency read latency来源有:\n memtable read sstable index read (bloom filter加快搜索) sstable search (binary search, hierarchy) sstable data copy (将data block从磁盘拷贝到内存) sstable deserialize (将硬盘中的数据反序列化为内存中的数据格式)  Design NoveLSM Design Principles 原则1：利用byte-addressability，减少序列化和反序列化成本 原则2：利用mutability和large capacity，减少compaction成本 磁盘中数据需要先读入内存，操作后再写入磁盘。 NVM中可以直接操作。\n原则3：利用in-place mutability，减少logging overhead和recovery cost 因为NVM的持久性，因此直接写入即可，不需要提前把日志持久化到磁盘\n原则4：利用low latency和high bandwidth，来并行化地读 Addressing (De)serialization Cost Immutable NVM skip list-based memtable. 设计immutable NVM skip list-based memtable，替代DRAM中的immutable memtable\nReducing Compaction Cost Mutability for persistent memtable 如图5b,交叉写入DRAM mutable memtable和large NVM mutable memtable\n 启动时首先初始化一个DRAM和NVM的mutable memtable 写入 DRAM mutable memtable，如果写满，冻结为immutable memtable，同时分配一个新的DRAM mutable memtable，同时将immutable memtable 进行compaction 刷入磁盘 写入 NVM mutable memtable，如果写满同上  也就是说 留给每个compaction过程的时间为 = 写满一个DRAM mutable memtable + 写满一个NVM mutable memtable的时间\n因此也就大大减少了系统停滞的可能性\nReducing Logging Cost Logging 写入DRAM的同时需要记录日志（带来了写放大） 写入NVM的直接in-place更新\nRecovery 故障时可能存在两种情况\n Vi写入DRAM memtable，但还没compaction Vi+1正在写入NVM memtable Vi已经写入NVM memtable Vi+1正在写入DRAM memtable  为了保证Recovery时的正确性：\n 对于每个DRAM memtable都有一个新的log file 正在写入NVM memtable时不需要log file，NVM memtable就可以被视作一个log file NVM log file有递增的version number  Recovery时按照version number递增顺序恢复\n发生故障时 写入DRAM的需要从logging文件进行Recovery。 写入NVM的memtable可以直接看作是一个日志文件，它同时需要一个存储跳表起始指针和其他元数据的额外文件从而在Recovery时定位数据。恢复时只需要进行内存映射即可。\nSupporting Read Parallelism Reducing read latency 常规的LSM中: 使用一个线程自上向下mutable memtable -\u0026gt; immutable memtable -\u0026gt; SSTable 在本设计中: DRAM memtable 和 NVM memtable使用一个线程 DRAM immutable 和 NVM immutable使用一个线程 SSTable使用一个线程\n因此时间从 $T_{read} ≈ T_{mem_{DRAM}} + T_{mem_{NVM}} + T_{imm} + T_{SST} $ 压缩为 $T_{read_parallel} ≈ max(T_{mem_{DRAM}} + T_{mem_{NVM}}, T_{imm}, T_{SST}) + C$ $C$是常量，代表了找到结果后停止其他线程所需的时间\nGuaranteeing version correctness for reads. 更高层(memtable-\u0026gt;immu-\u0026gt;sstable)往往是最新的数据，版本号最新。\n 负责更高层的thread找到结果后停止其他线程 负责更低层的thread找到结果后，先等待更高层的执行完  Optimistic parallelism and management. 多线程也带来了管理成本\n 把多线程分配到不同的cpu上 为DRAM和NVM memtable添加bloom filter，只有bloom filter miss的时候，才开启多线程查询，否则就只使用单线程。  ","permalink":"https://zhangyh.me/topics/paper/novelsm.html","summary":"Introduction 和目前的存储技术（例如flash、硬盘）相比， NVM有着以下的没有被LSM考虑的优点：\n 对于持久存储的随机访问的高性能 in-place update的低成本 (具体是?) 低时延、高带宽为application-level的并行化提供了机会  作者认为探索redesign适用于NVM的LSM是有意义的，而不是design a new data structure。 基于以下考量：\n 未来几年NVM和SSD共存，形成异质存储，而不是完全取代。redesign LSM可以在利用NVM的优点的前提下，同时不失去ssd和硬盘最优化的优势。 redesign lsm能为现有的应用提供向后兼容 保证批量写入NVM同样重要（NVM写延迟为DRAM的5-10倍）  Motivation 单纯的硬件NVM的读写是SSD的100倍左右，但在LevelDB在NVM和SSD上的差异只有4-7倍 因此可以说目前的LSM没有充分利用NVM的硬件优势，软件开销较大\nInsert Latency insert latency来源有三个方面：\n WAL memtable insert compaction   对于compaction 内存中的mutable memtable在写满之后会刷新成immutable memtable，由后台进程将其压缩进磁盘，同时新开一个mutable memtable，来接管写入 问题是新的mutable memtable写满之后，如果immutable memtable还没有刷到磁盘内，就会造成系统的停顿 当进行大量的写入时，这会成为insert latency的主要来源。\n 可能会说，让memtable大一点不就可以解决，但这会带来一系列的问题：\n 增大memtable会带来双倍的内存占用，因为mutable memtable和immutable memtable需要同时增大 WAL的磁盘占用也会更大，因为他需要容纳更多的指令 LSM为了性能并不commit log。   Third, LSMs suchas LevelDB and RocksDB do not enforce commits (sync) when writing to a log; as a result, an application crash or power-failure could lead to data loss","title":"Redesigning LSMs for nonvolatile memory with NoveLSM"},{"content":"Design Overview  Hybrid Table(HTable)  tuple heap in NVM Met-Cache in DRAM per-thread NVM-tuple managers.   Metadata in NVM Transaction and Indices in DRAM  NVM heap 所有的tuple持久化到NVM中的tuple heap，它由大小为2MB的pages组成 其中可能同时存在某个数据的多个版本 (tupleId, Tx-CTS)唯一确定一个tuple\n LP: 在commited transaction中最后一个被持久化的tuple，将该标记记为1 Tx-CTS: 每个事务在线程内都有唯一ID，单调递增。 Deleted: 被删除  Met-Cache NVM heap在DRAM中的缓存\n Clock bit: 用于Clock置换策略 Active bit: 事务正在使用该tuple Dirty bit: 被修改，当事务中途被absort，根据dirty位重新到NVM Heap获取tuple Copy bit: tuple被复制 CC-Meta：用于DRAM中的并发控制时，存储对应的信息。Zen中的并发控制完全实现在DRAM中，支持多种并发控制策略。  Indices in DRAM 在DRAM维护索引。crash后会重建。索引指向Met-Cache或者NVM heap中的tuple\nTransaction-Private Data 线程私有 用于事务并发访问 存储相应数据\nNVM Space Management 二级NVM空间管理器\n page-level负责分配NVM page tuple-level 线程本地的tuple管理器  Metadata Enhanced Tuple Cache Log-Free Persistent Transactions Normal Process Zen中的无锁事务处理包括三个阶段：\n Perform: 在DRAM中执行事务处理 Persist: 将最新的tuple持久化到NVM Maintenance: 垃圾收集过时的tuple  初始时，X=500, Y=100, Z=100 有事务：X账户转账给Y账户100，X账户转账给Z账户100 Perform  事务首先通过primary key查询索引，将NVM中的读到DRAM中.\n如果DRAM满需要按照指定的置换策略进行置换，被置换项不需要写入到NVM中。原因如下：1.该项可能为只读。2. 如果该项被已commited的事务修改，它一定已经写入到NVM中。3. 如果该项被abort的事务修改，则直接丢弃 在DRAM下的Met-Cache中执行并发控制的事务。 如果事务需要commit，则进行Persist阶段。 如果事务被abort，则把Met-Cache中该事务修改的标记为dirty的项重新从NVM中读到Met-Cache中，以方便下一次的重试。  该过程主要的过程：\n 将事务有关项从NVM加载到DRAM 修改索引 事务修改Met-Cache中的数据 Transaction跟踪读写集合  Persist 在不记录日志的条件下，持久化Perform阶段修改过的tuples\n 持久化tuples到新的slot中，原有的过时的tuples不改变 在持久化完成后，将该事务涉及的最后一个tuple的last persist标志位设置为1  如果持久化阶段发生crash，如果发现最后一个tuple的LP为1，则证明事务成功提交，如果没有，则丢弃上面被该事务写入的所有tuple。\nMaintenance 垃圾收集的两个场景：\n 提交事务时，对修改后的tuples进行了持久化，对之前版本的tuples进行垃圾收集。除非复制到DRAM中的tuples来源是其他线程，此时该线程NVM中肯定没有过时版本。 置换Met-Cache中的E时，如果E的copy标志位为1，则需要收集E在该线程NVM中的过时版本。  进入收集队列中不能直接free，需要根据CTS和全局最小的CTS进行判断\nFlexible Support for Concurrency Control Methods Zen使用Met-Cache中的CC-Meta字段来进行并发控制，它可以支持近10种并发控制方法，对于不同的方法，CC-Meta字段只需要存储需要设置的内容。\n分为单版本和多版本的并发控制\nCrash Recovery without Logs Crash发生时，DRAM中的Index、Transaction、Met-Cache等全部被清除，只有NVM中已经被持久化的数据。\n该算法在recovery时扫描NVM-tuple heap region来重建index，并进行空间整理.\n第一个循环先找当前有LP为1的最大CTS，当碰到小于该CTS的一定是已提交的，大于该CTS的不确定是否是可能absort的tuple\n因此在第二个循环中进行第二次判断，此时的最大CTS一定是全局最大，如果还有大于它的，说明其对应的事务被absort。\n该算法的正确性：\n 线程内的CTS是单调递增的 使用第二个循环检查不确定的项 该算法重建了索引 该算法是幂等的，它不修改任何已提交的tuple，如果recovery过程中发生crash，再次执行该算法即可。 二次recovery时看不到第一次crash导致的uncommited tuple  Support for Long Running Transactions 对于长事务，它使用的空间可能超出Met-Cache容量，此时，Zen将切换为exclusive模式\n长事务检测：\n Met-Cache空间用尽 垃圾回收队列超出阈值  Exclusive模式: 当侦测到长事务，将设置全局标志位G-EX，此时所有线程absort所有的常规事务，然后使用所有资源来执行长事务，执行完毕后，回到常规模式。\nLightweight NVM Space Management 二级NVM空间管理器\n page-level负责分配NVM page和page到HTable的映射，每个page为2MB，频率较低 tuple-level负责分配垃圾回收和NVM-tuple分配  ","permalink":"https://zhangyh.me/posts/paper/aug/zen/","summary":"Design Overview  Hybrid Table(HTable)  tuple heap in NVM Met-Cache in DRAM per-thread NVM-tuple managers.   Metadata in NVM Transaction and Indices in DRAM  NVM heap 所有的tuple持久化到NVM中的tuple heap，它由大小为2MB的pages组成 其中可能同时存在某个数据的多个版本 (tupleId, Tx-CTS)唯一确定一个tuple\n LP: 在commited transaction中最后一个被持久化的tuple，将该标记记为1 Tx-CTS: 每个事务在线程内都有唯一ID，单调递增。 Deleted: 被删除  Met-Cache NVM heap在DRAM中的缓存\n Clock bit: 用于Clock置换策略 Active bit: 事务正在使用该tuple Dirty bit: 被修改，当事务中途被absort，根据dirty位重新到NVM Heap获取tuple Copy bit: tuple被复制 CC-Meta：用于DRAM中的并发控制时，存储对应的信息。Zen中的并发控制完全实现在DRAM中，支持多种并发控制策略。  Indices in DRAM 在DRAM维护索引。crash后会重建。索引指向Met-Cache或者NVM heap中的tuple\nTransaction-Private Data 线程私有 用于事务并发访问 存储相应数据","title":"Zen: a high-throughput log-free OLTP engine for non-volatile main memory"},{"content":"Go | 内存分配 设计原理 Go的内存分配参考了TCMalloc的核心思想。\n 每一个线程都可以获得一个用于无锁分配小对象的缓存，这样可以让并行程序分配小对象（\u0026lt;=32KB）非常高效。 TCMalloc 管理的堆由一组页组成，一组连续的页面被表示为 span。当分配的对象大于 32KB，将使用页堆（Page Heap）进行内存分配。  相关struct mspan mspan是Go语言内存管理的基本单元。\ntype mspan struct { next *mspan // 链表指针 \tprev *mspan // 链表指针  startAddr uintptr // span 起始地址 \tnpages uintptr // page的数量  spanclass spanClass // size class and noscan (uint8) \tstate mSpanStateBox // span状态 \tlimit uintptr // end of data in span } 这里只列出了关心的主要字段。\n mspan使用 next和prev指针构成双向链表 startAddr确定了mspan所在内存的地址，npages确定了内存地址范围 每个mspan都管理这npages数量的page（注意这里的page不是操作系统的page，它是操作系统page的整数倍） state为mspan的状态，不细说。  spanClass 这是mspan中一个很核心的字段，spanClass是跨度类，它决定了mspan中管理的存储对象的大小和个数。\nGo语言中一共有68种跨度类，每个跨度类会存储特定大小的对象并且需要分配指定数量的page。\nclass_to_size表示每个跨度类的字节大小。 class_to_allocnpages表示每个跨度类需要分配page的数量。\nID为0的特殊跨度类，用于管理大对象。\n跨度类的最后一个二进制位是nospan标记，即表示对象是否包含指针，用于加快垃圾回收。\ntype spanClass uint8 // 前7位表示跨度类ID，最后一位标记是否包含指针  _NumSizeClasses = 68 var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var class_to_allocnpages = [_NumSizeClasses]uint8{0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 3, 2, 3, 4, 5, 6, 1, 7, 6, 5, 4, 3, 5, 7, 2, 9, 7, 5, 8, 3, 10, 7, 4} 每个mspan的内存都用于指定跨度类的内存分配。在分配内存时，首先需要选择最适合的跨度类，从而避免内存浪费。\nmcache mcache是线程缓存，它和GMP模型中的P绑定，主要用于为用户小于32KB的微、小对象分配内存。\n每个mcache有 $68 * 2$(_NumSizeClasses \u0026lt;\u0026lt; 1) 个 mspan。\n_NumSizeClasses = 68 numSpanClasses = _NumSizeClasses \u0026lt;\u0026lt; 1 type mcache struct { // 微为对象 \ttiny uintptr tinyoffset uintptr tinyAllocs uintptr // 小对象 \talloc [numSpanClasses]*mspan // spans to allocate from, indexed by spanClass } 上面我们说过跨度类共有68种，这里每个跨度类又分为有指针和无指针两类。\n对于小对象，在mcache中，为对象寻找mspan的流程如下：\n 计算对象所需内存大小size 根据size到size class映射，计算出所需的size class 根据size class和对象是否包含指针计算出span class 获取该span class指向的span。  但是如果对应的mspan没有剩余空间可被分配时，mcache就需要通过refill()函数向mcentral申请mspan,mcache拿到mspan后继续分配内存。\nmcentral type mcentral struct { spanclass spanClass partial [2]spanSet full [2]spanSet } 每个中心缓存都会管理某个跨度类的内存管理单元，它会同时持有两个 runtime.spanSet，分别存储包含空闲对象和不包含空闲对象的内存管理单元。\n当mcentral中的span不够用时，会找到mheap分配页数并获取新的mspan结构。\nmheap mheap是内存分配的核心结构体，每个Go语言程序有一个对应的全局变量。\ntype mheap struct { // lock must only be acquired on the system stack, otherwise a g \t// could self-deadlock if its stack grows with the lock held. \tlock mutex // arenas is the heap arena map. It points to the metadata for \t// the heap for every arena frame of the entire usable virtual \t// address space. \t// \t// Use arenaIndex to compute indexes into this array. \t// \t// For regions of the address space that are not backed by the \t// Go heap, the arena map contains nil. \t// \t// Modifications are protected by mheap_.lock. Reads can be \t// performed without locking; however, a given entry can \t// transition from nil to non-nil at any time when the lock \t// isn\u0026#39;t held. (Entries never transitions back to nil.) \t// \t// In general, this is a two-level mapping consisting of an L1 \t// map and possibly many L2 maps. This saves space when there \t// are a huge number of arena frames. However, on many \t// platforms (even 64-bit), arenaL1Bits is 0, making this \t// effectively a single-level map. In this case, arenas[0] \t// will never be nil. \tarenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena // central free lists for small size classes. \t// the padding makes sure that the mcentrals are \t// spaced CacheLinePadSize bytes apart, so that each mcentral.lock \t// gets its own cache line. \t// central is indexed by spanClass. \tcentral [numSpanClasses]struct { mcentral mcentral pad [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte } } mheap包含两个重要部分，一个是mcentral数组，它管理所有的跨度类内存。另一个是管理堆内存区域的arenas。\nGo 语言所有的内存空间都由如下所示的二维矩阵 heapArena 管理，这个二维矩阵管理的内存可以是不连续的，每一个 heapArena 都会管理 64MB 的操作系统的内存空间。\n内存分配  大于 32K 的大对象直接从 mheap 分配。 小于 16B 的使用 mcache 的微型分配器分配 对象大小在 16B ~ 32K 之间的的，首先通过计算使用的大小规格，然后使用 mcache 中对应大小规格的块分配 如果对应的大小规格在 mcache 中没有可用的块，则向 mcentral 申请 如果 mcentral 中没有可用的块，则向 mheap 申请，并根据 BestFit 算法找到最合适的 mspan。如果申请到的 mspan 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。 如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1MB）。 Go 会在操作系统分配超大的页（称作 arena）。分配一大批页会减少和操作系统通信的成本  References  https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator https://qiankunli.github.io/2020/11/22/go_mm.html https://zhuanlan.zhihu.com/p/352133292 https://www.linuxzen.com/go-memory-allocator-visual-guide.html https://segmentfault.com/a/1190000039815122 https://segmentfault.com/a/1190000023869256?utm_source=sf-similar-article  ","permalink":"https://zhangyh.me/posts/golang/go-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","summary":"Go | 内存分配 设计原理 Go的内存分配参考了TCMalloc的核心思想。\n 每一个线程都可以获得一个用于无锁分配小对象的缓存，这样可以让并行程序分配小对象（\u0026lt;=32KB）非常高效。 TCMalloc 管理的堆由一组页组成，一组连续的页面被表示为 span。当分配的对象大于 32KB，将使用页堆（Page Heap）进行内存分配。  相关struct mspan mspan是Go语言内存管理的基本单元。\ntype mspan struct { next *mspan // 链表指针 \tprev *mspan // 链表指针  startAddr uintptr // span 起始地址 \tnpages uintptr // page的数量  spanclass spanClass // size class and noscan (uint8) \tstate mSpanStateBox // span状态 \tlimit uintptr // end of data in span } 这里只列出了关心的主要字段。\n mspan使用 next和prev指针构成双向链表 startAddr确定了mspan所在内存的地址，npages确定了内存地址范围 每个mspan都管理这npages数量的page（注意这里的page不是操作系统的page，它是操作系统page的整数倍） state为mspan的状态，不细说。  spanClass 这是mspan中一个很核心的字段，spanClass是跨度类，它决定了mspan中管理的存储对象的大小和个数。","title":"Go | 内存分配"},{"content":"Go | context 什么是context context 主要用来在goroutine之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。\n可以通过以下个函数创建实现对应的功能:\n context.WithCancel(): 创建带有取消函数的context，上层goroutine调用cancelFunc函数，向下层传递取消信号 context.WithTimeout(): 创建带有超时的context，同时创建计时器，超时的时候调用context的cancelFunc；当然也可以主动调用cacelFunc context.WithDeadline(): 和带超时的context类似，实际底层WithTimeout就调用了WithDeadline； return WithDeadline(parent, time.Now().Add(timeout)) context.WithValue(): 创建带值的context  使用场景 1. 链路传值 func Test1() { ctx := context.WithValue(context.Background(), \u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) go handleChainA1(ctx) go handleChainA2(ctx) time.Sleep(2 * time.Second) } func handleChainA1(ctx context.Context) { log.Println(\u0026#34;handleChainA1\u0026#34;, ctx.Value(\u0026#34;key\u0026#34;)) go handleChainB(context.WithValue(ctx, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;)) } func handleChainA2(ctx context.Context) { log.Println(\u0026#34;handleChainA2\u0026#34;, ctx.Value(\u0026#34;key\u0026#34;)) } func handleChainB(ctx context.Context) { log.Println(\u0026#34;handleChainB\u0026#34;, ctx.Value(\u0026#34;key\u0026#34;)) log.Println(\u0026#34;handleChainB\u0026#34;, ctx.Value(\u0026#34;key2\u0026#34;)) } func main() { Test1()\t}  注意值的流向只能从上到下，上层context是获取不到下层传入的值的 传入的context不能为nil，可以传context.Background()或context.TODO()  2. 链路并发控制，释放资源 context最主要的作用是解决cancelation问题，也就是通过上层goroutine来释放下层goroutine。 可以把主要的并发模型归为两类，wait和cancel Wait主要通过sync.WaitGroup实现，Cancel则需要通过context.Context来实现\nfunc Test2() { ctx, cancel := context.WithCancel(context.Background()) go handle(ctx, 300*time.Millisecond) time.Sleep(1 * time.Second) cancel() // decide when to send cancel signal \tlog.Println(\u0026#34;main cancel\u0026#34;, ctx.Err()) } func handle(ctx context.Context, duration time.Duration) { i := 1 for { select { case \u0026lt;-ctx.Done(): log.Println(\u0026#34;handle cancel\u0026#34;, ctx.Err()) return default: // do work \tlog.Println(\u0026#34;do work\u0026#34;, i) i++ time.Sleep(duration) } } } func main() { Test2() time.Sleep(1 * time.Second) } 这里只是用了带有cancel信号的context，当然也可以使用带有超时和截止时间的context\n使用原则  不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context.TODO() 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据。例如：登陆的 session、cookie 等。 同一个 context 可能会被传递到多个 goroutine，别担心，context 是并发安全的。  References  https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/#61-%E4%B8%8A%E4%B8%8B%E6%96%87-context https://www.cnblogs.com/qcrao-2018/p/11007503.html https://36kr.com/p/1721518997505 https://faiface.github.io/post/context-should-go-away-go2/ https://golang.org/pkg/context/#example_WithDeadline https://xie.infoq.cn/article/3e18dd6d335d1a6ab552a88e8  ","permalink":"https://zhangyh.me/posts/golang/go-context/","summary":"Go | context 什么是context context 主要用来在goroutine之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。\n可以通过以下个函数创建实现对应的功能:\n context.WithCancel(): 创建带有取消函数的context，上层goroutine调用cancelFunc函数，向下层传递取消信号 context.WithTimeout(): 创建带有超时的context，同时创建计时器，超时的时候调用context的cancelFunc；当然也可以主动调用cacelFunc context.WithDeadline(): 和带超时的context类似，实际底层WithTimeout就调用了WithDeadline； return WithDeadline(parent, time.Now().Add(timeout)) context.WithValue(): 创建带值的context  使用场景 1. 链路传值 func Test1() { ctx := context.WithValue(context.Background(), \u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) go handleChainA1(ctx) go handleChainA2(ctx) time.Sleep(2 * time.Second) } func handleChainA1(ctx context.Context) { log.Println(\u0026#34;handleChainA1\u0026#34;, ctx.Value(\u0026#34;key\u0026#34;)) go handleChainB(context.WithValue(ctx, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;)) } func handleChainA2(ctx context.Context) { log.Println(\u0026#34;handleChainA2\u0026#34;, ctx.Value(\u0026#34;key\u0026#34;)) } func handleChainB(ctx context.Context) { log.Println(\u0026#34;handleChainB\u0026#34;, ctx.Value(\u0026#34;key\u0026#34;)) log.Println(\u0026#34;handleChainB\u0026#34;, ctx.Value(\u0026#34;key2\u0026#34;)) } func main() { Test1()\t}  注意值的流向只能从上到下，上层context是获取不到下层传入的值的 传入的context不能为nil，可以传context.","title":"Go | context"},{"content":"区别    方法 作用对象 返回值     new 值类型和用户定义类型 指向对象的指针   make 内置引用类型slice, map, channel 引用类型本身     值类型: 引用类型：\n new new用于为值类型或用户自定义的类型分配内存，并初始化零值，返回零值指针。\npackage main import ( \u0026#34;fmt\u0026#34; ) type Student struct { name string age int } func main() { var i *int // *i = 10 // panic: runtime error: invalid memory address or nil pointer dereference \tfmt.Println(i) // fmt.Println(*i)  num := new(int) fmt.Println(num) fmt.Println(*num) s := new(Student) fmt.Println(s) // \u0026amp;Student{} \tfmt.Println(*s) // Student{} } make make是为了初始化slice，map，channel这三种引用类型的。 针对这三种类型，分别调用runtime.makeslice，runtime.makemap，runtime.makechan函数。\nmake 相对于 new 来说，做的事情更多，new 只是开辟了内存空间， make 为更加复杂的数据结构开辟内存空间并对一些字段进行初始化\n总结  new用于为值类型或用户自定义的类型 make只能用于slice,map,channel  new一般不常用，通常直接使用结构体字面量\n","permalink":"https://zhangyh.me/posts/golang/go-make%E5%92%8Cnew/","summary":"区别    方法 作用对象 返回值     new 值类型和用户定义类型 指向对象的指针   make 内置引用类型slice, map, channel 引用类型本身     值类型: 引用类型：\n new new用于为值类型或用户自定义的类型分配内存，并初始化零值，返回零值指针。\npackage main import ( \u0026#34;fmt\u0026#34; ) type Student struct { name string age int } func main() { var i *int // *i = 10 // panic: runtime error: invalid memory address or nil pointer dereference \tfmt.Println(i) // fmt.Println(*i)  num := new(int) fmt.","title":"Go | make和new"},{"content":"之前对io多路复用有诸多疑惑，看了很多文章还是不甚了解——它是什么，它要解决什么问题。最近刚好需要分析golang网络轮询器，趁此机会，把io多路复用的相关内容都总结记录一下。\n为什么需要io多路复用模型? 当我们开启一个socket的时候，需要对发起的连接进行响应。\n阻塞io 阻塞io流程如图 如果使用阻塞io，我们可能会有下面类似的代码框架。\nlistenfd = socket() // 创建socket bind(listenfd, addr) // 将socketfd和服务器地址绑定 listend(listenfd) // 转换为监听套接字  while(1) { connfd = accept(listenfd) // 阻塞建立连接  new thread func(){ int n = read(connfd, buf) // 阻塞读数据  do_something() // 业务代码  close(connfd) //关闭连接套接字  } } 在accept()建立起连接后，我们会使用多线程来接手连接套接字connfd，阻塞的读取客户端发送来的内容。\n 每个连接都要开启一个线程来阻塞读取数据，但大多数线程都处于阻塞状态，造成了严重的线程浪费  非阻塞io 非阻塞io流程如图\n如果使用非阻塞io，我们可能会有下面类似的代码框架\nwhile(1) { connfd = accept(listenfd); // 阻塞建立连接  append(fds, connfd) for fd in fds { fcntl(connfd, F_SETFL, O_NONBLOCK); int n = read(connfd, buffer); if n != -1 { new thread doSomeThing(buf); // 利用读到的数据做些什么  } } } 将建立的连接放到数组中，然后进行轮询，当有能够读取到消息的时候，再开启新的线程进一步处理。\n 轮询时使用系统调用read，导致用户态和内核态的频繁切换  io多路复用 考虑到上述两种io模型的缺点，提出了io多路复用，使用一个线程监听多个fd，同时又能减少系统调用的次数。\nio多路复用包括三种模型select, poll和epoll。\nselect selet流程如图\nselect的思路是，将监听的fd数组从用户空间拷贝到内核空间，由内核负责遍历fd数组，确定哪些fd是可读写的，然后再将可读写的fd进行标记，拷贝标记数组到用户空间，并返回总的可读写的数量。再由用户进行遍历标记数组，处理相应的fd。\nselect由以下的问题：\n fd数组的大小有限制，最大为1024 fd数组从用户空间到内核空间的频繁拷贝 用户还是需要根据返回的可读fd大小，对标记数组进行遍历，判断具体可操作的fd是哪个  poll poll使用链表代替了数组，解决了最大监听数1024的限制，但频繁拷贝和遍历问题仍未得到解决\nepoll 针对select的三个问题，epoll进行了改进\n 可监控的fd数量没有限制 数据结构位于内核中，无需用户每次从用户空间拷贝，只需要告诉内核需要修改的部分即可。 内核只会将有io事件的fd返回给用户，避免了多余的遍历操作。  用户把需要监听的io事件添加到内核空间的红黑树中，对于每一个事件都会通过回调函数与网卡驱动建立回调关系，当相应的事件发生时，就会调用回调函数，通过回调函数把发生的事件添加到事件队列，当通过epoll_wait()检查是否有事件发生时，只需要检查队列是否为空即可，如果不为空，就把队列中的内容复制到用户态，同时将事件数量返回给用户。\nepoll还是用了共享内存加速了用户空间和内核空间的消息传递。\nepoll有LT(level trigger)和ET(edge trigger)两种模式：\n 水平触发(LT)：只要fd的事件还未处理（比如数据还没有读），每次epoll_wait都会返回该事件，提醒用户处理 边缘触发(ET): 当epoll_wait检测到事件并通知用户时，用户必须立马处理，否则下次也不会通知该事件。  该术语使用了脉冲信号相关的属于，很形象的表达了它们的功能。水平触发就是水平信号，只要事件不处理，就会一直发送该信号。边缘触发就是上升沿和下降沿，事件只会通知一次。\n总结     select poll epoll     操作方式 遍历 遍历 回调   数据结构 数组 链表 红黑树   时间复杂度 O(n) O(n) O(1)   最大fd数 1024 无上限 无上限   fd拷贝 每次拷贝所有数据 每次拷贝所有数据 拷贝相应的增删改操作    References 1. IO多路复用的三种机制Select，Poll，Epoll - 简书 2. I/O多路复用技术（multiplexing）是什么？ - 知乎 3. 彻底理解 IO 多路复用实现机制 4. 图解 | 原来这就是 IO 多路复用 5. 并发编程(IO多路复用) - 知乎 6. linux五种IO模型与事件驱动模型 - 云崖先生 - 博客园 7. IO复用之select、poll、epoll模型 - 知乎\n","permalink":"https://zhangyh.me/posts/misc/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","summary":"之前对io多路复用有诸多疑惑，看了很多文章还是不甚了解——它是什么，它要解决什么问题。最近刚好需要分析golang网络轮询器，趁此机会，把io多路复用的相关内容都总结记录一下。\n为什么需要io多路复用模型? 当我们开启一个socket的时候，需要对发起的连接进行响应。\n阻塞io 阻塞io流程如图 如果使用阻塞io，我们可能会有下面类似的代码框架。\nlistenfd = socket() // 创建socket bind(listenfd, addr) // 将socketfd和服务器地址绑定 listend(listenfd) // 转换为监听套接字  while(1) { connfd = accept(listenfd) // 阻塞建立连接  new thread func(){ int n = read(connfd, buf) // 阻塞读数据  do_something() // 业务代码  close(connfd) //关闭连接套接字  } } 在accept()建立起连接后，我们会使用多线程来接手连接套接字connfd，阻塞的读取客户端发送来的内容。\n 每个连接都要开启一个线程来阻塞读取数据，但大多数线程都处于阻塞状态，造成了严重的线程浪费  非阻塞io 非阻塞io流程如图\n如果使用非阻塞io，我们可能会有下面类似的代码框架\nwhile(1) { connfd = accept(listenfd); // 阻塞建立连接  append(fds, connfd) for fd in fds { fcntl(connfd, F_SETFL, O_NONBLOCK); int n = read(connfd, buffer); if n !","title":"理解io多路复用"},{"content":"【go调度】3. goroutine的创建和执行 参考上篇文章对文章对程序启动过程的分析，这里仍旧沿着上次分析的思路来分析main gorotine的创建和调度过程。\ngo程序的启动 TEXT runtime·rt0_go\u0026lt;ABIInternal\u0026gt;(SB),NOSPLIT,$0 .... // 初始化系统核心, 获取CPU的核数并放在global变量ncpu中  CALL\truntime·osinit(SB) // 初始化schedule  CALL\truntime·schedinit(SB) MOVQ\t$runtime·mainPC(SB), AX\t// entry  PUSHQ\tAX PUSHQ\t$0\t// arg size  // 创建新的goroutine来执行程序(main()函数)  CALL\truntime·newproc(SB) POPQ\tAX POPQ\tAX // 主线程进入调度循环，运行刚刚创建的 goroutine  CALL\truntime·mstart(SB) // mstart是不会返回的，如果返回，终止程序  CALL\truntime·abort(SB)\t// mstart should never return  RET main goroutine newproc() 该函数创建出main goroutine\nfunc newproc(siz int32, fn *funcval) { argp := add(unsafe.Pointer(\u0026amp;fn), sys.PtrSize) gp := getg() pc := getcallerpc() systemstack(func() { // 创建初始化好的newg \tnewg := newproc1(fn, argp, siz, gp, pc) // 把newg放入_p_的运行队列，初始化的时候一定是p的本地运行队列，其它时候可能因为本地队列满了而放入全局队列 \t_p_ := getg().m.p.ptr() runqput(_p_, newg, true) if mainStarted { wakep() } }) } newproc主要是对newproc1的封装。newproc首先获取要执行函数fn的参数地址argp，然后通过systemstack切换到g0栈去执行newproc1，然后把生成的g放入到绑定的p的本地队列中。\n需要注意在这里由于我们当前已经是g0，因此不需要切换，但由于newproc函数是通用的，在用户的goroutine中也会被调用，因此这里使用systemstack进行栈切换是有必要的。\n下面我们看一下newproc1做了什么。\n// 参数分别为函数fn,参数地址gp，参数以字节为单位的大小narg，调用者的g，调用者的pc func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) *g { _g_ := getg() // g0  .... _p_ := _g_.m.p.ptr() // 得到和当前线程绑定的p  newg := gfget(_p_) //从p的本地缓冲里获取一个没有使用的g，初始化时没有，返回nil  if newg == nil { //new一个g结构体对象，然后从堆上为其分配栈，栈大小为2k。_StackMin=2048  newg = malg(_StackMin) // 设置g的状态为_Gdead  casgstatus(newg, _Gidle, _Gdead) //放入全局变量allgs切片中  allgadd(newg) } .... // 调整newg的栈指针  totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize totalSize += -totalSize \u0026amp; (sys.SpAlign - 1) sp := newg.stack.hi - totalSize spArg := sp if usesLR { // caller\u0026#39;s LR  *(*uintptr)(unsafe.Pointer(sp)) = 0 prepGoExitFrame(sp) spArg += sys.MinFrameSize } // 如果有参数，将参数从g0栈拷贝到newg的栈  if narg \u0026gt; 0 { memmove(unsafe.Pointer(spArg), argp, uintptr(narg)) .... } // 重置newg.sched \tmemclrNoHeapPointers(unsafe.Pointer(\u0026amp;newg.sched), unsafe.Sizeof(newg.sched)) // 设置newg的参数 \tnewg.sched.sp = sp // sp \tnewg.stktopsp = sp newg.sched.pc = funcPC(goexit) + sys.PCQuantum // pc \tnewg.sched.g = guintptr(unsafe.Pointer(newg)) // go  // 模拟goexit调用fn，同时调整sp和pc,使pc指向fn \tgostartcallfn(\u0026amp;newg.sched, fn) newg.gopc = callerpc newg.ancestors = saveAncestors(callergp) newg.startpc = fn.fn if _g_.m.curg != nil { newg.labels = _g_.m.curg.labels } if isSystemGoroutine(newg, false) { atomic.Xadd(\u0026amp;sched.ngsys, +1) } // 设置g的状态为_Grunnable \tcasgstatus(newg, _Gdead, _Grunnable) .... return newg } 到此时，我们已经完成main goroutine的创建，我们参考这篇文章，给出当前的状态图。\n 这个图看起来比较复杂，因为表示指针的箭头实在是太多了，这里对其稍作一下解释。\n 首先，main goroutine对应的newg结构体对象的sched成员已经完成了初始化，图中只显示了pc和sp成员，pc成员指向了runtime.main函数的第一条指令，sp成员指向了newg的栈顶内存单元，该内存单元保存了runtime.main函数执行完成之后的返回地址，也就是runtime.goexit函数的第二条指令，预期runtime.main函数执行完返回之后就会去执行runtime.exit函数的CALL runtime.goexit1(SB)这条指令； 其次，newg已经放入与当前主线程绑定的p结构体对象的本地运行队列，因为它是第一个真正意义上的goroutine，还没有其它goroutine，所以它被放在了本地运行队列的头部； 最后，newg的m成员为nil，因为它还没有被调度起来运行，也就没有跟任何m进行绑定。   ![图片来源：https://www.cnblogs.com/abozhang/p/10825342.html](/img/main-goroutine.webp\nmstart() func mstart() { _g_ := getg() .... mstart1() // Exit this thread. \tif mStackIsSystemAllocated() { // Windows, Solaris, illumos, Darwin, AIX and Plan 9 always system-allocate \t// the stack, but put it in _g_.stack before mstart, \t// so the logic above hasn\u0026#39;t set osStack yet. \tosStack = true } mexit(osStack) } mstart没有什么多说的，主要封装了mstart1，我们下面分析mstart1。\nfunc mstart1() { _g_ := getg() if _g_ != _g_.m.g0 { throw(\u0026#34;bad runtime·mstart\u0026#34;) } // 保存调用者的pc和sp \tsave(getcallerpc(), getcallersp()) asminit() minit() .... schedule() } schedule() func schedule() { _g_ := getg() ..... // 通过调度获取下一个可执行的gp，具体的调度过程我们将来会分析  execute(gp, inheritTime) } execute() func execute(gp *g, inheritTime bool) { _g_ := getg() // g0  // 将gp和m绑定 \t// 设置gp状态为_Grunning  _g_.m.curg = gp gp.m = _g_.m casgstatus(gp, _Grunnable, _Grunning) gp.waitsince = 0 gp.preempt = false gp.stackguard0 = gp.stack.lo + _StackGuard .... // 实现了从g0到gp的切换 \tgogo(\u0026amp;gp.sched) } 此时还是在g0的栈上运行，通过gogo函数切换到gp的栈上运行\ngogo()  gogo函数也是通过汇编语言编写的，这里之所以需要使用汇编，是因为goroutine的调度涉及不同执行流之间的切换，前面我们在讨论操作系统切换线程时已经看到过，执行流的切换从本质上来说就是CPU寄存器以及函数调用栈的切换，然而不管是go还是c这种高级语言都无法精确控制CPU寄存器的修改，因而高级语言在这里也就无能为力了，只能依靠汇编指令来达成目的。\n # restore state from Gobuf; longjmp TEXT runtime·gogo(SB), NOSPLIT, $16-8 #buf = \u0026amp;gp.sched MOVQ buf+0(FP), BX # BX = buf #gobuf-\u0026gt;g --\u0026gt; dx register MOVQ gobuf_g(BX), DX # DX = gp.sched.g #下面这行代码没有实质作用，检查gp.sched.g是否是nil，如果是nil进程会crash死掉 MOVQ 0(DX), CX # make sure g != nil get_tls(CX) #把要运行的g的指针放入线程本地存储，这样后面的代码就可以通过线程本地存储 #获取到当前正在执行的goroutine的g结构体对象，从而找到与之关联的m和p MOVQ DX, g(CX) #恢复调度上下文到CPU相关寄存器 MOVQ gobuf_sp(BX), SP # restore SP #把CPU的SP寄存器设置为sched.sp，完成了栈的切换 MOVQ gobuf_ret(BX), AX MOVQ gobuf_ctxt(BX), DX MOVQ gobuf_bp(BX), BP #清空sched的值，因为我们已把相关值放入CPU对应的寄存器了，不再需要，这样做可以少gc的工作量 MOVQ $0, gobuf_sp(BX) # clear to help garbage collector MOVQ $0, gobuf_ret(BX) MOVQ $0, gobuf_ctxt(BX) MOVQ $0, gobuf_bp(BX) #把sched.pc值放入BX寄存器 MOVQ gobuf_pc(BX), BX #JMP把BX寄存器的包含的地址值放入CPU的IP寄存器，于是，CPU跳转到该地址继续执行指令， JMP BX gogo的作用为：\n 把gp.sched的成员恢复到CPU的寄存器完成状态以及栈的切换； 跳转到gp.sched.pc所指的指令地址（runtime.main）处执行。  runtime.main() // The main goroutine. func main() { g := getg() // Racectx of m0-\u0026gt;g0 is used only as the parent of the main goroutine. \t// It must not be used for anything else. \tg.m.g0.racectx = 0 if sys.PtrSize == 8 { maxstacksize = 1000000000 // 64位栈最大为1G \t} else { maxstacksize = 250000000 } // Allow newproc to start new Ms. \tmainStarted = true if GOARCH != \u0026#34;wasm\u0026#34; { // 切换到g0栈去运行监控线程sysmon \tatomic.Store(\u0026amp;sched.sysmonStarting, 1) systemstack(func() { newm(sysmon, nil, -1) }) } doInit(\u0026amp;runtime_inittask) // runtime init  gcenable() // 开启gc  fn := main_main // 调用main.main函数 \tfn() //进入系统调用，退出进程，可以看出main goroutine并未返回，而是直接进入系统调用退出进程了\t\texit(0) for { var x *int32 *x = 0 } } runtime.main函数主要工作流程如下：\n 启动一个sysmon系统监控线程，该线程负责整个程序的gc、抢占调度以及netpoll等功能的监控，在抢占调度一章我们再继续分析sysmon是如何协助完成goroutine的抢占调度的； 执行runtime包的初始化； 执行main包以及main包import的所有包的初始化； 执行main.main函数； 从main.main函数返回后调用exit系统调用退出进程；  非main goroutine main goroutine结束时会执行exit(0)直接结束进程，从而使得所有其余的goroutine被终止。 而非main goroutine结束时则会执行goexit()函数完成清理工作。\ngoexit() TEXT runtime·goexit(SB),NOSPLIT,$0-0 BYTE $0x90 // NOP  CALL runtime·goexit1(SB) // does not return  BYTE $0x90 // NOP 调用runtime.goexit1()函数\nfunc goexit1() { if raceenabled { // 静态检查 \tracegoend() } if trace.enabled { // trace检查 \ttraceGoEnd() } mcall(goexit0) // 执行goexit0 } goexit1函数通过调用mcall从当前运行的go goroutine切换到g0，然后在g0栈上调用和执行goexit0这个函数。\n// goexit continuation on g0. func goexit0(gp *g) { _g_ := getg() //g0  // 状态改为_Gdead \tcasgstatus(gp, _Grunning, _Gdead) if isSystemGoroutine(gp, false) { atomic.Xadd(\u0026amp;sched.ngsys, -1) } // 清理gp \tgp.m = nil locked := gp.lockedm != 0 gp.lockedm = 0 _g_.m.lockedg = 0 gp.preemptStop = false gp.paniconfault = false gp._defer = nil // should be true already but just in case. \tgp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data. \tgp.writebuf = nil gp.waitreason = 0 gp.param = nil gp.labels = nil gp.timer = nil //g-\u0026gt;m = nil, m-\u0026gt;currg = nil 解绑g和m之关系 \tdropg() // g放入p的freeg队列，方便下次重用，免得再去申请内存，提高效率 \tgfput(_g_.m.p.ptr(), gp) // 再次回到调度函数 \tschedule() } 下面开始在g0栈执行goexit0函数，该函数完成最后的清理工作：\n 把g的状态从_Grunning变更为_Gdead； 然后把g的一些字段清空成0值； 调用dropg函数解除g和m之间的关系，其实就是设置g-\u0026gt;m = nil, m-\u0026gt;currg = nil； 把g放入p的freeg队列缓存起来供下次创建g时快速获取而不用从内存分配。freeg就是g的一个对象池； 调用schedule函数再次进行调度；  总结  我们用上图来总结一下工作线程的执行流程：\n 初始化，调用mstart函数； 调用mstart1函数，在该函数中调用save函数设置g0.sched.sp和g0.sched.pc等调度信息，其中g0.sched.sp指向mstart函数栈帧的栈顶； 依次调用schedule-\u0026gt;execute-\u0026gt;gogo函数执行调度； 运行用户的goroutine代码； 用户goroutine代码执行过程中调用runtime中的某些函数，然后这些函数调用mcall切换到g0.sched.sp所指的栈并最终再次调用schedule函数进入新一轮调度，之后工作线程一直循环执行着3～5这一调度循环直到进程退出为止。   ","permalink":"https://zhangyh.me/posts/golang/go%E8%B0%83%E5%BA%A63-goroutine%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E6%89%A7%E8%A1%8C/","summary":"【go调度】3. goroutine的创建和执行 参考上篇文章对文章对程序启动过程的分析，这里仍旧沿着上次分析的思路来分析main gorotine的创建和调度过程。\ngo程序的启动 TEXT runtime·rt0_go\u0026lt;ABIInternal\u0026gt;(SB),NOSPLIT,$0 .... // 初始化系统核心, 获取CPU的核数并放在global变量ncpu中  CALL\truntime·osinit(SB) // 初始化schedule  CALL\truntime·schedinit(SB) MOVQ\t$runtime·mainPC(SB), AX\t// entry  PUSHQ\tAX PUSHQ\t$0\t// arg size  // 创建新的goroutine来执行程序(main()函数)  CALL\truntime·newproc(SB) POPQ\tAX POPQ\tAX // 主线程进入调度循环，运行刚刚创建的 goroutine  CALL\truntime·mstart(SB) // mstart是不会返回的，如果返回，终止程序  CALL\truntime·abort(SB)\t// mstart should never return  RET main goroutine newproc() 该函数创建出main goroutine\nfunc newproc(siz int32, fn *funcval) { argp := add(unsafe.","title":"Go调度 | 3. goroutine的创建和执行"},{"content":"【go调度】4. 调度策略 前文分析了scheduler的初始化以及goroutine创建和执行，略过了调度策略的内容。\n有关调度策略的部分主要位于调度函数schedule()中，本文将具体分析。\nschedule() func schedule() { _g_ := getg() top: var gp *g .... // 全局队列  if gp == nil { // 为了公平起见，每调度61次，就去全局队列优先获取goroutine  // 避免两个本地队列中的goroutine循环调度,导致全局队列中的goroutine得不到运行  if _g_.m.p.ptr().schedtick%61 == 0 \u0026amp;\u0026amp; sched.runqsize \u0026gt; 0 { lock(\u0026amp;sched.lock) gp = globrunqget(_g_.m.p.ptr(), 1) unlock(\u0026amp;sched.lock) } } // 本地队列  if gp == nil { // 从本地队列优先获取goroutine  gp, inheritTime = runqget(_g_.m.p.ptr()) } // 本地和全局都没有获取到goroutine，就需要从其他的p本地队列中偷取  // 如果偷取不到当前线程会block，知道返回可用的goroutine  if gp == nil { gp, inheritTime = findrunnable() // blocks until work is available  } .... execute(gp, inheritTime) } 从p的本地队列获取goroutine 从源码上看，p的本地队列包括两部分，一个是runnext所指向的goroutine，另一个就是由runq,runhead和runtail组成的无锁队列。\n具体实现的函数为runqget()\nfunc runqget(_p_ *p) (gp *g, inheritTime bool) { // 如果runnext不为空，则返回runnext指向的goroutine  // 这里使用乐观锁CAS  for { next := _p_.runnext if next == 0 { break } if _p_.runnext.cas(next, 0) { return next.ptr(), true } } // 从循环队列中获取goroutine  for { h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with other consumers  t := _p_.runqtail if t == h { return nil, false } gp := _p_.runq[h%uint32(len(_p_.runq))].ptr() if atomic.CasRel(\u0026amp;_p_.runqhead, h, h+1) { // cas-release, commits consume  return gp, false } } } 从schedt的全局队列获取goroutine  需要注意，每个工作线程每进行61次调度就需要优先从全局运行队列中获取\n // 从全局队列中取最多max个G到p的本地队列中 func globrunqget(_p_ *p, max int32) *g { assertLockHeld(\u0026amp;sched.lock) if sched.runqsize == 0 { return nil } // 根据p的数量平分全局队列中的G  n := sched.runqsize/gomaxprocs + 1 if n \u0026gt; sched.runqsize { n = sched.runqsize } if max \u0026gt; 0 \u0026amp;\u0026amp; n \u0026gt; max { n = max } if n \u0026gt; int32(len(_p_.runq))/2 { n = int32(len(_p_.runq)) / 2 } sched.runqsize -= n // 直接返回gp，其余的通过runqput放到p的本地队列中去  gp := sched.runq.pop() n-- for ; n \u0026gt; 0; n-- { gp1 := sched.runq.pop() runqput(_p_, gp1, false) } return gp } working-stealing策略  findrunnable主要负责偷取G，代码十分繁杂，这里只分析我们主要关心的部分，忽略gc和netpoll相关的内容\n // Finds a runnable goroutine to execute. // Tries to steal from other P\u0026#39;s, get g from local or global queue, poll network. func findrunnable() (gp *g, inheritTime bool) { _g_ := getg() // The conditions here and in handoffp must agree: if  // findrunnable would return a G to run, handoffp must start  // an M.  top: _p_ := _g_.m.p.ptr() .... // 再次检查本地队列  if gp, inheritTime := runqget(_p_); gp != nil { return gp, inheritTime } // 再次检查全局队列  if sched.runqsize != 0 { lock(\u0026amp;sched.lock) gp := globrunqget(_p_, 0) unlock(\u0026amp;sched.lock) if gp != nil { return gp, false } } .... // 从其他工作的p偷取  procs := uint32(gomaxprocs) ranTimer := false // 偷取的两个前提条件  // 1. 状态为 非自旋  // 2. 已经有很多工作线程在自旋偷取工作了，自己就先歇会  if !_g_.m.spinning \u0026amp;\u0026amp; 2*atomic.Load(\u0026amp;sched.nmspinning) \u0026gt;= procs-atomic.Load(\u0026amp;sched.npidle) { goto stop } // 设置m状态为spinning  if !_g_.m.spinning { _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) } // 从其他p的本地队列偷取goroutine  const stealTries = 4 for i := 0; i \u0026lt; stealTries; i++ { stealTimersOrRunNextG := i == stealTries-1 for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() { if sched.gcwaiting != 0 { goto top } p2 := allp[enum.position()] if _p_ == p2 { continue } .... if !idlepMask.read(enum.position()) { if gp := runqsteal(_p_, p2, stealTimersOrRunNextG); gp != nil { return gp, false } } } } if ranTimer { // Running a timer may have made some goroutine ready.  goto top } stop: .... // Before we drop our P, make a snapshot of the allp slice,  // which can change underfoot once we no longer block  // safe-points. We don\u0026#39;t need to snapshot the contents because  // everything up to cap(allp) is immutable.  allpSnapshot := allp .... // return P and block  lock(\u0026amp;sched.lock) if sched.gcwaiting != 0 || _p_.runSafePointFn != 0 { unlock(\u0026amp;sched.lock) goto top } if sched.runqsize != 0 { gp := globrunqget(_p_, 0) unlock(\u0026amp;sched.lock) return gp, false } // 解除当前线程和P之间的绑定，准备休眠  if releasep() != _p_ { throw(\u0026#34;findrunnable: wrong p\u0026#34;) } // 把p放入空闲队列  pidleput(_p_) unlock(\u0026amp;sched.lock) wasSpinning := _g_.m.spinning if _g_.m.spinning { // m即将睡眠  _g_.m.spinning = false if int32(atomic.Xadd(\u0026amp;sched.nmspinning, -1)) \u0026lt; 0 { throw(\u0026#34;findrunnable: negative nmspinning\u0026#34;) } } // check all runqueues once again  for id, _p_ := range allpSnapshot { if !idlepMaskSnapshot.read(uint32(id)) \u0026amp;\u0026amp; !runqempty(_p_) { lock(\u0026amp;sched.lock) _p_ = pidleget() unlock(\u0026amp;sched.lock) if _p_ != nil { acquirep(_p_) if wasSpinning { _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) } goto top } break } } .... // 休眠  stopm() goto top }  正在偷取g的工作线程处于spinning状态。 偷取时通过一种伪随机的方式遍历allp，然后在内层循环中通过runqsteal实现steal逻辑  // Steal half of elements from local runnable queue of p2 // and put onto local runnable queue of p. // Returns one of the stolen elements (or nil if failed). func runqsteal(_p_, p2 *p, stealRunNextG bool) *g { t := _p_.runqtail n := runqgrab(p2, \u0026amp;_p_.runq, t, stealRunNextG) if n == 0 { return nil } n-- gp := _p_.runq[(t+n)%uint32(len(_p_.runq))].ptr() if n == 0 { return gp } h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with consumers \tif t-h+n \u0026gt;= uint32(len(_p_.runq)) { throw(\u0026#34;runqsteal: runq overflow\u0026#34;) } atomic.StoreRel(\u0026amp;_p_.runqtail, t+n) // store-release, makes the item available for consumption \treturn gp } 从p2中偷取一半的g放到p中\n如果无论如何都没有获取到可以运行的goroutine，则调用stopm进入睡眠状态，等待被其他的工作线程唤醒。\n// Stops execution of the current m until new work is available. // Returns with acquired P. func stopm() { _g_ := getg() if _g_.m.locks != 0 { throw(\u0026#34;stopm holding locks\u0026#34;) } if _g_.m.p != 0 { throw(\u0026#34;stopm holding p\u0026#34;) } if _g_.m.spinning { throw(\u0026#34;stopm spinning\u0026#34;) } lock(\u0026amp;sched.lock) mput(_g_.m) unlock(\u0026amp;sched.lock) mPark() acquirep(_g_.m.nextp.ptr()) _g_.m.nextp = 0 }  stopm的核心是调用mput把m结构体对象放入sched的midle空闲队列，然后通过notesleep(\u0026amp;m.park)函数让自己进入睡眠状态。 note是go runtime实现的一次性睡眠和唤醒机制，一个线程可以通过调用notesleep(*note)进入睡眠状态，而另外一个线程则可以通过notewakeup(*note)把其唤醒。note的底层实现机制跟操作系统相关，不同系统使用不同的机制。 回到stopm，当从notesleep函数返回后，需要再次绑定一个p，然后返回到findrunnable函数继续重新寻找可运行的goroutine，一旦找到可运行的goroutine就会返回到schedule函数，并把找到的goroutine调度起来运行，如何把goroutine调度起来运行的代码我们已经分析过了。现在继续看notesleep函数。\n ","permalink":"https://zhangyh.me/posts/golang/go%E8%B0%83%E5%BA%A64-%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5/","summary":"【go调度】4. 调度策略 前文分析了scheduler的初始化以及goroutine创建和执行，略过了调度策略的内容。\n有关调度策略的部分主要位于调度函数schedule()中，本文将具体分析。\nschedule() func schedule() { _g_ := getg() top: var gp *g .... // 全局队列  if gp == nil { // 为了公平起见，每调度61次，就去全局队列优先获取goroutine  // 避免两个本地队列中的goroutine循环调度,导致全局队列中的goroutine得不到运行  if _g_.m.p.ptr().schedtick%61 == 0 \u0026amp;\u0026amp; sched.runqsize \u0026gt; 0 { lock(\u0026amp;sched.lock) gp = globrunqget(_g_.m.p.ptr(), 1) unlock(\u0026amp;sched.lock) } } // 本地队列  if gp == nil { // 从本地队列优先获取goroutine  gp, inheritTime = runqget(_g_.m.p.ptr()) } // 本地和全局都没有获取到goroutine，就需要从其他的p本地队列中偷取  // 如果偷取不到当前线程会block，知道返回可用的goroutine  if gp == nil { gp, inheritTime = findrunnable() // blocks until work is available  } .","title":"Go调度 | 4. 调度策略"},{"content":"准备写一个有关go schedule系列的文章，目前已经有很多这方面的内容，但为了记录学习过程和未来复习，我还是决定亲自输出写东西。 该系列预期包括以下内容：\n GMP模型 scheduler的初始化 main goroutine和非main goroutine的启动和结束 如何调度 \u0026ndash; 全局队列，局部队列，working-stealing 何时调度 \u0026ndash;被动，主动，抢占式  创建go routine start=\u0026gt;start: 开始\rop1=\u0026gt;operation: 获取go func()的func和args\rop2=\u0026gt;operation: 切换至g0，使用g0创建对应的G\rop3=\u0026gt;operation: gfget(p) 从当前的P获取空闲G;\rop4=\u0026gt;operation: 参数复制到G,清除堆,pc:func,sp:goexit1\rop5=\u0026gt;operation: runqput(p,newg,true); 将G加入P的runnable数组;\rend=\u0026gt;end: 结束\rstart-\u0026gt;op1\rop1-\u0026gt;op2\rop2-\u0026gt;op3\rop3-\u0026gt;op4\rop4-\u0026gt;op5\rop5-\u0026gt;end\r创建P References  Go 语言调度器与 Goroutine 实现原理 | Go 语言设计与实现 golang 源码学习之GMP (goroutine) - 简书 go/runtime2.go at master · golang/go [译]Go 调度器: M, P 和 G | 鸟窝 Golang调度器源码分析 Golang的协程调度器原理及GMP设计思想？ · Golang修养之路 · 看云 Golang源码探索(二) 协程的实现原理 - q303248153 - 博客园  ","permalink":"https://zhangyh.me/posts/golang/gmp%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/","summary":"准备写一个有关go schedule系列的文章，目前已经有很多这方面的内容，但为了记录学习过程和未来复习，我还是决定亲自输出写东西。 该系列预期包括以下内容：\n GMP模型 scheduler的初始化 main goroutine和非main goroutine的启动和结束 如何调度 \u0026ndash; 全局队列，局部队列，working-stealing 何时调度 \u0026ndash;被动，主动，抢占式  创建go routine start=\u0026gt;start: 开始\rop1=\u0026gt;operation: 获取go func()的func和args\rop2=\u0026gt;operation: 切换至g0，使用g0创建对应的G\rop3=\u0026gt;operation: gfget(p) 从当前的P获取空闲G;\rop4=\u0026gt;operation: 参数复制到G,清除堆,pc:func,sp:goexit1\rop5=\u0026gt;operation: runqput(p,newg,true); 将G加入P的runnable数组;\rend=\u0026gt;end: 结束\rstart-\u0026gt;op1\rop1-\u0026gt;op2\rop2-\u0026gt;op3\rop3-\u0026gt;op4\rop4-\u0026gt;op5\rop5-\u0026gt;end\r创建P References  Go 语言调度器与 Goroutine 实现原理 | Go 语言设计与实现 golang 源码学习之GMP (goroutine) - 简书 go/runtime2.go at master · golang/go [译]Go 调度器: M, P 和 G | 鸟窝 Golang调度器源码分析 Golang的协程调度器原理及GMP设计思想？ · Golang修养之路 · 看云 Golang源码探索(二) 协程的实现原理 - q303248153 - 博客园  ","title":"GMP源码分析"},{"content":"本节深入先从宏观上介绍GMP模型，然后再通过源码进行深入了解。\n线程和协程 协程是用户态的线程，他的管理和调度都是在用户态进行的，协程与线程相比有以下的优势：\n 内存占用 线程内存占用约为4MB，且大小固定。协程内存占用约为2KB，并且是弹性可拓展的。 线程的内存分配往往一方面会造成内存的浪费，另一方面也会有栈溢出的风险。 创建和切换 线程的创建和切换都需要在内核态进行，并且线程切换时有很多寄存器需要进行现场保护。 而协程的创建和切换都是用户态的，并且线程保护的内容相对较少  GMP模型  G: goroutine协程,即我们定义的 go func(){} P: processor处理器，是一种抽象的、用于G执行的局部资源 M: machine，也即thread，对应实际的内核线程\n GMP结构 这部分主要从源码层面分析GMP的结构\nG结构 我们暂时忽略一些对我们分析没有影响的字段。\ntype g struct { stack stack // goroutine 使用的栈[stack.lo, stack.hi] \tstackguard0 uintptr stackguard1 uintptr // 用于栈空间的动态变化  m *m // 与当前g绑定的m  sched gobuf // goroutine的运行线程，主要为寄存器信息 \tparam unsafe.Pointer // warkup 唤醒时传递的参数 \tatomicstatus uint32 // goroutine的状态 \tgoid int64 // goroutine id \tschedlink guintptr // 指向全局goroutine队列中的的下一个  // go阻塞的时间和原因 \twaitsince int64 // approx time when the g become blocked \twaitreason waitReason // if status==Gwaiting  // 抢占调度相关 \tpreempt bool // preemption signal, duplicates stackguard0 = stackpreempt \tpreemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule \tpreemptShrink bool // shrink stack at synchronous safe point } 其中atomicstatus存储了goroutine的状态，这里列举一些重要的状态\n _Gidle:\t刚刚被分配并且还没有被初始化 _Grunnable:\t没有执行代码，没有栈的所有权，存储在运行队列中 _Grunning:\t可以执行代码，拥有栈的所有权，被赋予了内核线程 M 和处理器 P _Gsyscall:\t正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程 但是不在运行队列上 _Gwaiting: 由于运行时而被阻塞，没有执行用户代码并且不在运行队列上，但是可能存在Channel 的等待队列上 _Gdead: 没有被使用，没有执行代码，可能有分配的栈 _Gcopystack: 栈正在被拷贝，没有执行代码，不在运行队列上 _Gpreempted: 由于抢占而被阻塞，没有执行用户代码并且不在运行队列上，等待唤醒 _Gscan: GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在  M 结构 M代表操作系统的内核线程，他最多能创建10000个，但最多只有GOMAXPROCS个线程同时执行。如果不显式的指定，GOMAXPROCS默认为cpu的核心数。\ngolang使用runtime.m来表示操作系统线程。\ntype m struct { g0 *g\t// 用于执行调度指令的 goroutine,g0是特殊的goroutine \tgsignal *g\t// 处理 signal 的 g \ttls [6]uintptr\t// 线程本地存储,主要为了实现m和工作线程的一一对应 \tcurg *g\t// 当前运行的用户 goroutine \tp puintptr\t// 执行go代码时持有的 p (如果没有执行则为 nil) \tspinning bool\t// m 当前没有运行 work 且正处于寻找 work 的活跃状态 \talllink *m\t// 所有的m都在allm 上 \tmcache *mcache // 持有当前线程上进行内存分配的本地缓存  ... }  g0 是一个运行时中比较特殊的 Goroutine，它会深度参与运行时的调度过程，包括 Goroutine 的创建、大内存分配和 CGO 函数的执行。在后面的小节中，我们会经常看到 g0 的身影。\n P 结构 P是goroutine和实际工作线程之间的中间层，它持有一个G的本地队列。\n我们重点关注以下字段\ntype p struct { m muintptr //与当前p绑定的m  runqhead uint32 // 本地队列，无锁访问 \trunqtail uint32 runq [256]guintptr runnext guintptr ... } runtime.p 结构体中的状态 status 字段会是以下五种中的一种：\n _Pidle: 处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空 _Prunning: 被线程 M 持有，并且正在执行用户代码或者调度器 _Psyscall: 没有执行用户代码，当前线程陷入系统调用 _Pgcstop: 被线程 M 持有，当前处理器由于垃圾回收被停止 _Pdead: 当前处理器已经不被使用  调度器sched的结构 type schedt struct { lock mutex pidle puintptr\t// 空闲 p 链表 \tnpidle uint32\t// 空闲 p 数量 \tnmspinning uint32\t// 自旋状态的 M 的数量 \trunq gQueue\t// 全局 runnable G 队列 \trunqsize int32 gFree struct {\t// 有效 dead G 的全局缓存. \tlock mutex stack gList\t// 包含栈的 Gs \tnoStack gList\t// 没有栈的 Gs \tn int32 } sudoglock mutex\t// sudog 结构的集中缓存 \tsudogcache *sudog deferlock mutex\t// 不同大小的有效的 defer 结构的池 \tdeferpool [5]*_defer ... } 一些重要的全局信息 allgs []*g // 保存所有的g allm *m // 所有的m构成的一个链表，包括下面的m0 allp []*p // 保存所有的p，len(allp) == gomaxprocs  ncpu int32 // 系统中cpu核的数量，程序启动时由runtime代码初始化 gomaxprocs int32 // p的最大值，默认等于ncpu，但可以通过GOMAXPROCS修改  m0 m // 代表进程的主线程 g0 g // m0的g0，也就是m0.g0 = \u0026amp;g0 References  go/runtime2.go at master · golang/go Go 语言调度器与 Goroutine 实现原理 | Go 语言设计与实现 Golang的协程调度器原理及GMP设计思想？ · Golang修养之路 · 看云 Goroutine调度器(一)：P、M、G关系  ","permalink":"https://zhangyh.me/posts/golang/go%E8%B0%83%E5%BA%A61-gmp%E6%A8%A1%E5%9E%8B/","summary":"本节深入先从宏观上介绍GMP模型，然后再通过源码进行深入了解。\n线程和协程 协程是用户态的线程，他的管理和调度都是在用户态进行的，协程与线程相比有以下的优势：\n 内存占用 线程内存占用约为4MB，且大小固定。协程内存占用约为2KB，并且是弹性可拓展的。 线程的内存分配往往一方面会造成内存的浪费，另一方面也会有栈溢出的风险。 创建和切换 线程的创建和切换都需要在内核态进行，并且线程切换时有很多寄存器需要进行现场保护。 而协程的创建和切换都是用户态的，并且线程保护的内容相对较少  GMP模型  G: goroutine协程,即我们定义的 go func(){} P: processor处理器，是一种抽象的、用于G执行的局部资源 M: machine，也即thread，对应实际的内核线程\n GMP结构 这部分主要从源码层面分析GMP的结构\nG结构 我们暂时忽略一些对我们分析没有影响的字段。\ntype g struct { stack stack // goroutine 使用的栈[stack.lo, stack.hi] \tstackguard0 uintptr stackguard1 uintptr // 用于栈空间的动态变化  m *m // 与当前g绑定的m  sched gobuf // goroutine的运行线程，主要为寄存器信息 \tparam unsafe.Pointer // warkup 唤醒时传递的参数 \tatomicstatus uint32 // goroutine的状态 \tgoid int64 // goroutine id \tschedlink guintptr // 指向全局goroutine队列中的的下一个  // go阻塞的时间和原因 \twaitsince int64 // approx time when the g become blocked \twaitreason waitReason // if status==Gwaiting  // 抢占调度相关 \tpreempt bool // preemption signal, duplicates stackguard0 = stackpreempt \tpreemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule \tpreemptShrink bool // shrink stack at synchronous safe point } 其中atomicstatus存储了goroutine的状态，这里列举一些重要的状态","title":"Go调度 | 1. GMP模型"},{"content":"上篇文章结尾告诉我们了几个重要的全局变量，本篇文章会用到\nallm *m // 所有的m构成的一个链表，包括下面的m0 allp []*p // 保存所有的p，len(allp) == gomaxprocs  ncpu int32 // 系统中cpu核的数量，程序启动时由runtime代码初始化 gomaxprocs int32 // p的最大值，默认等于ncpu，但可以通过GOMAXPROCS修改  m0 m // 代表进程的主线程 g0 g // m0的g0，也就是m0.g0 = \u0026amp;g0 go程序的启动 当我们运行一个main()函数来启动整个go程序的时候，他的启动流程是什么，这里我们从源码方面仔细分析下整个流程。\n对于linux下的程序来说，入口文件在runtime/rt0_linux_amd64.s，\n 具体我们是如何判断入口文件的，可以参考这篇文章，文章简单易懂\n TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8 JMP\t_rt0_amd64(SB) 跳转到runtime/asm_amd64.s文件的_rt0_amd64(SB)函数\n// 操作系统内核传递过来的参数argc和argv数组的地址分别放在DI和SI寄存器中 // 然后跳转到 rt0_go 去执行 TEXT _rt0_amd64(SB),NOSPLIT,$-8 MOVQ\t0(SP), DI\t// argc \tLEAQ\t8(SP), SI\t// argv \tJMP\truntime·rt0_go(SB) 跳转到runtime·rt0_go函数，我们保留该函数的主要流程\nTEXT runtime·rt0_go\u0026lt;ABIInternal\u0026gt;(SB),NOSPLIT,$0 // 拷贝argc和argv到指定位置  MOVQ\tDI, AX\t// argc  MOVQ\tSI, BX\t// argv  SUBQ\t$(4*8+7), SP\t// 2args 2auto  ANDQ\t$~15, SP MOVQ\tAX, 16(SP) MOVQ\tBX, 24(SP) // 为g0分配栈空间，g0的栈一般相对较大  // 之后会专门写一篇分析g0的文章  MOVQ\t$runtime·g0(SB), DI LEAQ\t(-64*1024+104)(SP), BX MOVQ\tBX, g_stackguard0(DI) MOVQ\tBX, g_stackguard1(DI) MOVQ\tBX, (g_stack+stack_lo)(DI) MOVQ\tSP, (g_stack+stack_hi)(DI) // ... 省略检验cpu信息的过程  // 初始化tls  // DI = \u0026amp;m0.tls，取 m0 的 tls 成员的地址到 DI 寄存器  // 调用 settls 设置线程本地存储，settls 函数的参数在 DI 寄存器中  // 之后，直接调用get_tls(), 通过 fs 段寄存器找到 m.tls  LEAQ\truntime·m0+m_tls(SB), DI CALL\truntime·settls(SB) // ... 省略验证tls是否能正常工作的过程  // 把 g0 的地址保存在线程本地存储里面，也就是 m0.tls[0]=\u0026amp;g0  get_tls(BX) LEAQ\truntime·g0(SB), CX MOVQ\tCX, g(BX) LEAQ\truntime·m0(SB), AX // m-\u0026gt;g0 = g0  MOVQ\tCX, m_g0(AX) // g0-\u0026gt;m = m0  MOVQ\tAX, g_m(CX) CLD\t// convention is D is always left cleared  CALL\truntime·check(SB) MOVL\t16(SP), AX\t// copy argc  MOVL\tAX, 0(SP) MOVQ\t24(SP), AX\t// copy argv  MOVQ\tAX, 8(SP) CALL\truntime·args(SB) // 初始化系统核心, 获取CPU的核数并放在global变量ncpu中，  CALL\truntime·osinit(SB) // 初始化scheduler，将是本文重点分析的内容  CALL\truntime·schedinit(SB) MOVQ\t$runtime·mainPC(SB), AX\t// entry  PUSHQ\tAX PUSHQ\t$0\t// arg size  // 创建新的goroutine来执行程序(main()函数)  CALL\truntime·newproc(SB) POPQ\tAX POPQ\tAX // 主线程进入调度循环，运行刚刚创建的 goroutine  CALL\truntime·mstart(SB) // mstart是不会返回的，如果返回，终止程序  CALL\truntime·abort(SB)\t// mstart should never return  RET 根据汇编代码，总结整个流程\n 为g0，并分配栈空间 g0和m0相互绑定 // m.g0 = g0; g0.m = m0 osinit() OS初始化 schedinit() 调度器初始化 newproc() 将runtime.main作为参数创建goroutine mstart() 主线程进入调度循环  当初对tls的内容不了解，这里详细解释下\n set_tls()通过系统调用把m0.tls[1]的地址设置成了fs段的段基址。CPU中有个叫fs的段寄存器与之对应，而每个线程都有自己的一组CPU寄存器值，操作系统在把线程调离CPU运行时会帮我们把所有寄存器中的值保存在内存中，调度线程起来运行时又会从内存中把这些寄存器的值恢复到CPU。这样，在此之后，工作线程代码就可以通过fs寄存器来找到m.tls\n scheinit() 省略我们暂时不关心的代码\n// The bootstrap sequence is: // //\tcall osinit //\tcall schedinit //\tmake \u0026amp; queue new G //\tcall runtime·mstart // // The new G calls runtime·main. ///runtime/proc.go func schedinit() { ... // 获取g0  _g_ := getg() ... // 设置最大 M 数量  sched.maxmcount = 10000 ... // 栈和内存初始化  stackinit() mallocinit() ... // 初始化m0  mcommoninit(_g_.m) ... //参数和环境初始化  goargs() goenvs() ... // 设置 P 的数量  procs := ncpu // 通过环境变量设置P的数量  if n, ok := atoi32(gogetenv(\u0026#34;GOMAXPROCS\u0026#34;)); ok \u0026amp;\u0026amp; n \u0026gt; 0 { procs = n } if procresize(procs) != nil {//创建和初始化全局变量allp  throw(\u0026#34;unknown runnable goroutine during bootstrap\u0026#34;) } ... } mcommoninit() ——初始化m0 主要用来初始化mp，包括设置id、设置random、设置gsignal、挂载到全局m中\n// 可以为m显式的传过来一个id，或者为-1 func mcommoninit(mp *m, id int64) { _g_ := getg() // g0 stack won\u0026#39;t make sense for user (and is not necessary unwindable).  if _g_ != _g_.m.g0 { callers(1, mp.createstack[:]) } lock(\u0026amp;sched.lock) // 检查id  if id \u0026gt;= 0 { mp.id = id } else { mp.id = mReserveID() //当id为-1时，通过该函数获取一个可用id  } // 设置random  mp.fastrand[0] = uint32(int64Hash(uint64(mp.id), fastrandseed)) mp.fastrand[1] = uint32(int64Hash(uint64(cputicks()), ^fastrandseed)) if mp.fastrand[0]|mp.fastrand[1] == 0 { mp.fastrand[1] = 1 } //创建用于信号处理的gsignal，只是简单的从堆上分配一个g结构体对象,然后把栈设置好就返了  mpreinit(mp) if mp.gsignal != nil { mp.gsignal.stackguard1 = mp.gsignal.stack.lo + _StackGuard } // 将 m 挂到全局变量 allm 上，allm 是一个指向 m 的的指针。  mp.alllink = allm atomicstorep(unsafe.Pointer(\u0026amp;allm), unsafe.Pointer(mp)) unlock(\u0026amp;sched.lock) if iscgo || GOOS == \u0026#34;solaris\u0026#34; || GOOS == \u0026#34;illumos\u0026#34; || GOOS == \u0026#34;windows\u0026#34; { mp.cgoCallers = new(cgoCallers) } } procresize() ——初始化allp  procresize()通过GOMAXPROC可以动态的调整p的总个数，但其中涉及的问题比较复杂。 在这里我们只考虑初始化时的代码\n func procresize(nprocsint32) *p { old := gomaxprocs//系统初始化时 gomaxprocs = 0  ...... // Grow allp if necessary.  if nprocs \u0026gt; int32(len(allp)) { //初始化时 len(allp) == 0  // Synchronize with retake, which could be running  // concurrently since it doesn\u0026#39;t run on a P.  lock(\u0026amp;allpLock) if nprocs \u0026lt;= int32(cap(allp)) { allp = allp[:nprocs] } else { //初始化时进入此分支，创建allp 切片  nallp:=make([]*p, nprocs) // Copy everything up to allp\u0026#39;s cap so we  // never lose old allocated Ps.  copy(nallp, allp[:cap(allp)]) allp=nallp } unlock(\u0026amp;allpLock) } // initialize new P\u0026#39;s  //循环创建nprocs个p并完成基本初始化  for i := int32(0); i\u0026lt;nprocs; i++{ pp := allp[i] if pp == nil{ pp=new(p)//调用内存分配器从堆上分配一个struct p  pp.id=i pp.status=_Pgcstop ...... atomicstorep(unsafe.Pointer(\u0026amp;allp[i]), unsafe.Pointer(pp)) } ...... } ...... _g_:=getg() // _g_ = g0  if _g_.m.p != 0 \u0026amp;\u0026amp; _g_.m.p.ptr().id \u0026lt; nprocs {//初始化时m0-\u0026gt;p还未初始化，所以不会执行这个分支  // continue to use the current P  _g_.m.p.ptr().status=_Prunning _g_.m.p.ptr().mcache.prepareForSweep() } else {//初始化时执行这个分支  // release the current P and acquire allp[0]  if _g_.m.p != 0 {//初始化时这里不执行  _g_.m.p.ptr().m=0 } _g_.m.p=0 _g_.m.mcache = nil p := allp[0] p.m = 0 p.status = _Pidle acquirep(p) //把p和m0关联起来，其实是这两个strct的成员相互赋值  if trace.enabled { traceGoStart() } } //下面这个for 循环把所有空闲的p放入空闲链表  var runnablePs *p for i := nprocs-1; i \u0026gt;= 0; i-- { p := allp[i] if _g_.m.p.ptr() == p {//allp[0]跟m0关联了，所以是不能放任  continue } p.status = _Pidle if runqempty(p) {//初始化时除了allp[0]其它p全部执行这个分支，放入空闲链表  pidleput(p) } else { ...... } } ...... return runnablePs }  通过启动时候的schedinit调用procresize生成对应个数的P。因为可以通过runtime.GOMAXPROCS来动态修改P的个数，所以在procresize中会对P数组进行调整，或新增P或减少P。被减少的P会将自身的runable、runnext、gfree移到全局去。\n 如果当前P不在多余的P中，则状态为running 如果当前P在多余的P中，则将当前M和P解绑，再将M和P数组的第一P绑定，并设为running 除了当前P外；所有P都设为idle，如果P中没有runnable,则将P加入全局空闲P,否则获取全局空闲M和P绑定。   References  golang 源码学习之GMP (goroutine) - 简书 开天辟地 —— Go scheduler 初始化（二） Go语言goroutine调度器初始化(12)  ","permalink":"https://zhangyh.me/posts/golang/go%E8%B0%83%E5%BA%A62-scheduler%E5%88%9D%E5%A7%8B%E5%8C%96/","summary":"上篇文章结尾告诉我们了几个重要的全局变量，本篇文章会用到\nallm *m // 所有的m构成的一个链表，包括下面的m0 allp []*p // 保存所有的p，len(allp) == gomaxprocs  ncpu int32 // 系统中cpu核的数量，程序启动时由runtime代码初始化 gomaxprocs int32 // p的最大值，默认等于ncpu，但可以通过GOMAXPROCS修改  m0 m // 代表进程的主线程 g0 g // m0的g0，也就是m0.g0 = \u0026amp;g0 go程序的启动 当我们运行一个main()函数来启动整个go程序的时候，他的启动流程是什么，这里我们从源码方面仔细分析下整个流程。\n对于linux下的程序来说，入口文件在runtime/rt0_linux_amd64.s，\n 具体我们是如何判断入口文件的，可以参考这篇文章，文章简单易懂\n TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8 JMP\t_rt0_amd64(SB) 跳转到runtime/asm_amd64.s文件的_rt0_amd64(SB)函数\n// 操作系统内核传递过来的参数argc和argv数组的地址分别放在DI和SI寄存器中 // 然后跳转到 rt0_go 去执行 TEXT _rt0_amd64(SB),NOSPLIT,$-8 MOVQ\t0(SP), DI\t// argc \tLEAQ\t8(SP), SI\t// argv \tJMP\truntime·rt0_go(SB) 跳转到runtime·rt0_go函数，我们保留该函数的主要流程\nTEXT runtime·rt0_go\u0026lt;ABIInternal\u0026gt;(SB),NOSPLIT,$0 // 拷贝argc和argv到指定位置  MOVQ\tDI, AX\t// argc  MOVQ\tSI, BX\t// argv  SUBQ\t$(4*8+7), SP\t// 2args 2auto  ANDQ\t$~15, SP MOVQ\tAX, 16(SP) MOVQ\tBX, 24(SP) // 为g0分配栈空间，g0的栈一般相对较大  // 之后会专门写一篇分析g0的文章  MOVQ\t$runtime·g0(SB), DI LEAQ\t(-64*1024+104)(SP), BX MOVQ\tBX, g_stackguard0(DI) MOVQ\tBX, g_stackguard1(DI) MOVQ\tBX, (g_stack+stack_lo)(DI) MOVQ\tSP, (g_stack+stack_hi)(DI) // .","title":"Go调度 | 2. scheduler初始化"},{"content":"【译】SliceTricks  原文链接: https://github.com/golang/go/wiki/SliceTricks\n go官方给出了许多slice操作的tricks，这里记录一下，并在最后给出examples\nAppendVector a = append(a, b...) Copy // 正常拷贝 b := make([]int, len(a)) copy(b, a) // 正常拷贝的one-line实现，但实际上边速度要慢一点 b = append(make([]int, 0, len(a)), a...) // 如果拷贝后还需要添加更多的元素，可以使用这种方式 // 但通常来说上面的方式更快 append([]int(nil), a...) // or append(a[:0:0], a...) Cut a = append(a[:i], a[j:]...) Delete a = append(a[:i], a[i:]...) Delete without preserving order a[i] = a[len(a) - 1] a = a[:len(a) - 1] [admonition color=\u0026ldquo;red\u0026rdquo;]如果数组类型为指针，或者时带有指针的结构体,那么上述的操作很可能会导致内存泄露的发生:一些元素仍然被a引用，但没有被垃圾回收器回收。可以使用以下的方式避免内存泄漏[/admonition]\n Cut\n copy(a[i:], a[j:]) for k, n := len(a)-j+i, len(a); k \u0026lt; n; k++ { a[k] = nil // or the zero value of T } a = a[:len(a)-j+i]  Delete\n copy(a[i:], a[i+1:]) a[len(a)-1] = nil // or the zero value of T a = a[:len(a)-1]  Delete without preserving order\n a[i] = a[len(a)-1] a[len(a)-1] = nil a = a[:len(a)-1] Expand a = append(a[:i], append(make([]T, j), a[i:]...)...) Extend a = append(a, make([]T, j)...) Filter(in place) n := 0 for _, x := range a { if keep(x) { a[n] = x n++ } } a = a[:n] Insert a = append(a[:i], append([]T{x}, a[i:]...)...) [admonition color=\u0026ldquo;red\u0026rdquo;]此种方式会创建一个新的slice，我们可以通过以下方式避免[/admonition]\na = append(a, 0) copy(a[i+1:] ,a[i:]) a[i] = value InsertVector a = append(a[:i], append(b, a[i:]...)...) Push a = append(a, x) Pop x, a = a[len(a) - 1], a[:len(a) - 1] Push Front/Unshift a = append([]T{x}, a...) Pop Front/Shift x, a = a[0], a[1:] Additional Tricks Filtering without allocating slice使用相同的底层数组，因此可以重用该数组来进行filter操作。当然，原始的内容会被修改。\nb := a[:0] for _, x := range a { if f(x) { b = append(b, x) } } 对于必须进行垃圾回收的元素，可以在上述代码后添加以下代码，进行元素的垃圾回收。\nfor i := len(b); i \u0026lt; len(a); i++ { a[i] = nil } Reversing for i := len(a)/2-1; i \u0026gt;= 0; i-- { opp := len(a)-1-i a[i], a[opp] = a[opp], a[i] } 也可以使用以下方式。（个人比较喜欢以下这种，更直观）\nfor left, right := 0, len(a)-1; left \u0026lt; right; left, right = left+1, right-1 { a[left], a[right] = a[right], a[left] } Shuffling Fisher–Yates 算法\n 从go 1.10，可以使用 math/rand.Shuffle\n for i := len(a) - 1; i \u0026gt; 0; i-- { j := rand.Intn(i + 1) a[i], a[j] = a[j], a[i] } Batching with minimal allocation 如果想在一个超大的slice做批处理，这是很有用的\nactions := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} batchSize := 3 batches := make([][]int, 0, (len(actions) + batchSize - 1) / batchSize) for batchSize \u0026lt; len(actions) { actions, batches = actions[batchSize:], append(batches, actions[0:batchSize:batchSize]) } batches = append(batches, actions) // [[0 1 2] [3 4 5] [6 7 8] [9]] In-place deduplicate (comparable)  in-place 去重\n import \u0026#34;sort\u0026#34; in := []int{3,2,1,4,3,2,1,4,1} sort.Ints(in) j := 0 for i := 1; i \u0026lt; len(in); i++ { if in[j] == in[i] { continue } j++ in[j] = in[i] } result := in[:j+1] fmt.Println(result) // [1 2 3 4] Move to front, or prepend if not present, in place if possible. func moveToFront(needle string, haystack []string) []string { if len(haystack) != 0 \u0026amp;\u0026amp; haystack[0] == needle { return haystack } prev := needle for i, elem := range haystack { switch { case i == 0: haystack[0] = needle prev = elem case elem == needle: haystack[i] = prev return haystack default: haystack[i] = prev prev = elem } } return append(haystack, prev) } haystack := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;} // [a b c d e] haystack = moveToFront(\u0026#34;c\u0026#34;, haystack) // [c a b d e] haystack = moveToFront(\u0026#34;f\u0026#34;, haystack) // [f c a b d e] Sliding window func slidingWindow(size int, input []int) [][]int { if len(input) \u0026lt;= size { return [][]int{input} } r := make([][]int, 0, len(input)-size+1) for i, j := 0, size; j \u0026lt;= len(input); i, j = i+1, j+1 { r = append(r, input[i:j]) } return r } Examples package main import (\u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; ) func main() { var a, b []int fmt.Println(\u0026#34;1. AppendVector\u0026#34;) a, b = []int{1, 2, 3, 4}, []int{5, 6, 7} a = append(a, b...) // a: [1 2 3 4 5 6 7]  fmt.Println(\u0026#34;2. Copy\u0026#34;) a = []int{1, 2, 3, 4} // 1.make + copy \tb = make([]int, len(a)) copy(b, a) // 2. one-line implementation \tb = append(make([]int, 0, len(a)), a...) // 3. another one \tb = append([]int(nil), a...) // a: [1 2 3 4], b: [1 2 3 4]  fmt.Println(\u0026#34;3. Cut\u0026#34;) a = []int{1, 2, 3, 4} a = append(a[:1], a[2:]...) // a: [1 3 4]  fmt.Println(\u0026#34;4. Delete\u0026#34;) a = []int{1, 2, 3, 4} a = append(a[:2], a[2:]...) // a: [1 2 3 4]  fmt.Println(\u0026#34;5. Delete without preserving order\u0026#34;) a = []int{1, 2, 3, 4} a[0] = a[len(a)-1] a = a[:len(a)-1] // a: [4 2 3]  fmt.Println(\u0026#34;6. Expand\u0026#34;) a = []int{1, 2, 3, 4} a = append(a[:2], append(make([]int, 10), a[2:]...)...) // a: [1 2 0 0 0 0 0 0 0 0 0 0 3 4]  fmt.Println(\u0026#34;7. Extend\u0026#34;) a = []int{1, 2, 3, 4} a = append(a, make([]int, 10)...) // a: [1 2 3 4 0 0 0 0 0 0 0 0 0 0]  fmt.Println(\u0026#34;8. Filter\u0026#34;) a = []int{1, 2, 3, 4} keep := func(x int) bool { return x%2 == 0 } n := 0 for _, x := range a { if keep(x) { a[n] = x n++ } } a = a[:n] // a: [2 4]  fmt.Println(\u0026#34;9. Insert\u0026#34;) a = []int{1, 2, 3, 4} a = append(a[:1], append([]int{10}, a[1:]...)...) // a: [1 10 2 3 4]  fmt.Println(\u0026#34;10. Insert Vector\u0026#34;) a, b = []int{1, 2, 3, 4}, []int{5, 6, 7} a = append(a[:1], append(b, a[1:]...)...) // a: [1 5 6 7 2 3 4]  fmt.Println(\u0026#34;11. Push\u0026#34;) a = []int{1,2,3,4} a = append(a, 10) // a: [1 2 3 4 10]  fmt.Println(\u0026#34;12. Pop\u0026#34;) var x int a = []int{1,2,3,4} x, a = a[len(a) - 1], a[:len(a) - 1] // x: 4, a: [1 2 3]  fmt.Println(\u0026#34;13. Push Front\u0026#34;) a = []int{1,2,3,4} a = append([]int{10}, a...) // a: [10 1 2 3 4]  fmt.Println(\u0026#34;14. Pop Front\u0026#34;) a = []int{1,2,3,4} x, a = a[0], a[1:] // x: 1, a: [2 3 4]  fmt.Println(\u0026#34;15. Filtering without allocation\u0026#34;) a = []int{1,2,3,4} b = a[:0] for _, v := range a { if keep(v) { b = append(b, v) } } for i := len(b); i \u0026lt; len(a); i++ { a[i] = 0 } // a: [2 4 0 0], b: [2 4]  fmt.Println(\u0026#34;16. Reversing\u0026#34;) a = []int{1,2,3,4} for l, r := 0, len(a) - 1; l \u0026lt; r; l, r = l + 1, r - 1 { a[l], a[r] = a[r], a[l] } // a: [4 3 2 1]  fmt.Println(\u0026#34;17. Shuffling\u0026#34;) a = []int{1,2,3,4} rand.Shuffle(len(a), func(i, j int) { a[i], a[j] = a[j], a[i] }) // a: [1 2 4 3] } References  https://github.com/golang/go/wiki/SliceTricks  ","permalink":"https://zhangyh.me/posts/golang/slicetricks/","summary":"【译】SliceTricks  原文链接: https://github.com/golang/go/wiki/SliceTricks\n go官方给出了许多slice操作的tricks，这里记录一下，并在最后给出examples\nAppendVector a = append(a, b...) Copy // 正常拷贝 b := make([]int, len(a)) copy(b, a) // 正常拷贝的one-line实现，但实际上边速度要慢一点 b = append(make([]int, 0, len(a)), a...) // 如果拷贝后还需要添加更多的元素，可以使用这种方式 // 但通常来说上面的方式更快 append([]int(nil), a...) // or append(a[:0:0], a...) Cut a = append(a[:i], a[j:]...) Delete a = append(a[:i], a[i:]...) Delete without preserving order a[i] = a[len(a) - 1] a = a[:len(a) - 1] [admonition color=\u0026ldquo;red\u0026rdquo;]如果数组类型为指针，或者时带有指针的结构体,那么上述的操作很可能会导致内存泄露的发生:一些元素仍然被a引用，但没有被垃圾回收器回收。可以使用以下的方式避免内存泄漏[/admonition]\n Cut\n copy(a[i:], a[j:]) for k, n := len(a)-j+i, len(a); k \u0026lt; n; k++ { a[k] = nil // or the zero value of T } a = a[:len(a)-j+i]  Delete","title":"Go | SliceTricks"},{"content":"《人民币汇率与人民币国际化》-翟东升 总结翟东升老师的《人民币汇率与人民币国际化》基础课所讲的内容和知识点\n1. 对人民币汇率的错误预测 看空人民币的五个错误理由 看空人民的观点错在哪 人民币是强势货币 2. 汇率的影响因素  短期看市场情绪，中期看政府调控，长期看市场\n 影响长期汇率的直接因素 长期来看影响汇率最直接最有效的因素就是一个国家可贸易品的价格水平。可贸易品的加权平均价决定了汇率。\n 两国之间的可贸易品价格如果差距太大，就会进行倒买倒卖，最终实现抛补平衡\n 技术水平 和 人口老龄化 决定了可贸易品的价格，从而影响了汇率 (参考日本)\n影响汇率的六个深层因素   国家能力 政府财政开支占国家GDP的比例越高，汇率往往越坚挺。\n政府需要提供各种有效的公共产品(医疗、市场、教育、基础设施、贸易协定、治安秩序、商业秩序)。各种企业的成功离不开政府提供的公共产品。\n  贸易开放度 出口所占比例。\n   凡是想做空日元的都没有什么好下场\n  要素特征 出口贸易品类型。 出口以能源、原材料、大宗商品、矿石等为主，汇率呈顺周期。 出口制成品为主，汇率呈逆周期。(汇率下跌，出口工业制成品获得价格优势，贸易顺差扩大，汇率获得上涨动能)\n  文明类型 汇率最坚挺的两大文明：新教文明和东亚文明 鼓励生产，不鼓励消费\n   新教文明：西欧、北欧、北美洲、大洋洲 东亚文明：日本、朝鲜半岛、中国大陆、中国台湾、中国香港、新加坡、越南\n 比较软的货币所属文明：小乘佛教 不鼓励生产，不鼓励消费\n贬值很厉害的货币所属文明：罗马天主教、东正教和伊斯兰教 不鼓励生产，鼓励消费\n人均智商 宗教严肃度  海外投资的汇率风险 中国企业和资本出海需要重点防范：目标国的汇率风险 (结合上面所讲的因素进行思考)\n","permalink":"https://zhangyh.me/posts/thinking/%E4%BA%BA%E6%B0%91%E5%B8%81%E6%B1%87%E7%8E%87%E4%B8%8E%E4%BA%BA%E6%B0%91%E5%B8%81%E5%9B%BD%E9%99%85%E5%8C%96/","summary":"《人民币汇率与人民币国际化》-翟东升 总结翟东升老师的《人民币汇率与人民币国际化》基础课所讲的内容和知识点\n1. 对人民币汇率的错误预测 看空人民币的五个错误理由 看空人民的观点错在哪 人民币是强势货币 2. 汇率的影响因素  短期看市场情绪，中期看政府调控，长期看市场\n 影响长期汇率的直接因素 长期来看影响汇率最直接最有效的因素就是一个国家可贸易品的价格水平。可贸易品的加权平均价决定了汇率。\n 两国之间的可贸易品价格如果差距太大，就会进行倒买倒卖，最终实现抛补平衡\n 技术水平 和 人口老龄化 决定了可贸易品的价格，从而影响了汇率 (参考日本)\n影响汇率的六个深层因素   国家能力 政府财政开支占国家GDP的比例越高，汇率往往越坚挺。\n政府需要提供各种有效的公共产品(医疗、市场、教育、基础设施、贸易协定、治安秩序、商业秩序)。各种企业的成功离不开政府提供的公共产品。\n  贸易开放度 出口所占比例。\n   凡是想做空日元的都没有什么好下场\n  要素特征 出口贸易品类型。 出口以能源、原材料、大宗商品、矿石等为主，汇率呈顺周期。 出口制成品为主，汇率呈逆周期。(汇率下跌，出口工业制成品获得价格优势，贸易顺差扩大，汇率获得上涨动能)\n  文明类型 汇率最坚挺的两大文明：新教文明和东亚文明 鼓励生产，不鼓励消费\n   新教文明：西欧、北欧、北美洲、大洋洲 东亚文明：日本、朝鲜半岛、中国大陆、中国台湾、中国香港、新加坡、越南\n 比较软的货币所属文明：小乘佛教 不鼓励生产，不鼓励消费\n贬值很厉害的货币所属文明：罗马天主教、东正教和伊斯兰教 不鼓励生产，鼓励消费\n人均智商 宗教严肃度  海外投资的汇率风险 中国企业和资本出海需要重点防范：目标国的汇率风险 (结合上面所讲的因素进行思考)","title":"人民币汇率与人民币国际化—翟东升"}]